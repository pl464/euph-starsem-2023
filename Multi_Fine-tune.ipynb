{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317efaf3-7eac-4593-8959-0d2dcd941ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, \n",
    "                          Trainer)\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import logging\n",
    "from typing import Union\n",
    "import os\n",
    "\n",
    "# for updating an external results .csv file\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7f177d-eb18-4cbe-99fb-afd1e3efe22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Runs fine-tuning once. Preprocesses data, then creates and trains a Trainer object (be sure to specify TrainingArguments).\n",
    "Returns a trained model, based on TrainingArguments. Metrics are output to an external `results.csv` in the same directory.\n",
    "\n",
    "ARGS:\n",
    "    - trainfile (str): the .csv file containing the training data\n",
    "    - testfile (str): the .csv file containing the training data\n",
    "    - output_dir (str): the output directory where saved models will be output, if saving is enabled\n",
    "    - MODEL_NAME (str): name of the HuggingFace model (https://huggingface.co/) to be loaded and fine-tuned\n",
    "    - TRAINING_ARGS (TrainingArguments): set of parameters for training\n",
    "    - logger (Union[logging.Logger, None]), optional: a Logger object which will log certain steps\n",
    "    - seed (int): random seed \n",
    "\n",
    "RETURNS: \n",
    "    - model (AutoModelForSequenceClassification): the trained model, based on training_args\n",
    "\"\"\"\n",
    "def run_trainer(trainfile: str, testfile: str, output_dir: str, \n",
    "                MODEL_NAME: str, TRAINING_ARGS: TrainingArguments,\n",
    "                logger: Union[logging.Logger, None], \n",
    "                seed: int = 42) -> AutoModelForSequenceClassification:\n",
    "    \n",
    "    log = logging.getLogger(__name__) if logger is None else logger\n",
    "    \n",
    "    # sanity checks\n",
    "    for i in [trainfile, testfile, output_dir]:\n",
    "        assert os.path.exists(i), f\"File/Directory {i} does not exist\"\n",
    "    \n",
    "    # log.info('loading dataset...')\n",
    "    dataset = load_dataset(\"csv\", data_files={\"train\": trainfile, \n",
    "                                              \"test\": testfile})\n",
    "\n",
    "    # define tokenizer and tokenize datasets\n",
    "    # log.info('loading tokenizer...')\n",
    "    tokenizer = AutoTokenizer.from_pretrained(os.getenv('MODEL_NAME'), max_length=512)\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "    # log.info('tokenizing datasets...')\n",
    "    tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    # load training arguments\n",
    "    training_args = TRAINING_ARGS\n",
    "    \n",
    "    # load model\n",
    "    # log.info('loading model...')\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    # define evaluation metrics\n",
    "    metric_f1 = evaluate.load(\"f1\")\n",
    "    metric_pr = evaluate.load(\"precision\")\n",
    "    metric_re= evaluate.load(\"recall\")\n",
    "    # metric_acc = evaluate.load(\"accuracy\")\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        \n",
    "        f1 = metric_f1.compute(predictions=predictions, \n",
    "                               references=labels, \n",
    "                               average='macro')\n",
    "        \n",
    "        recall = metric_re.compute(predictions=predictions, \n",
    "                                   references=labels)\n",
    "        \n",
    "        precision = metric_pr.compute(predictions=predictions, \n",
    "                                      references=labels)\n",
    "        \n",
    "        # ***** update an external results .csv file ***** # \n",
    "        tn, fp, fn, tp = confusion_matrix(labels, predictions).ravel()\n",
    "        if ('results.csv' not in os.listdir()):\n",
    "            df = pd.DataFrame(columns=['f1', 'precision', 'recall', 'tn', 'fp', 'fn', 'tp', 'preds'])\n",
    "        else:\n",
    "            df = pd.read_csv('results.csv', index_col=0)\n",
    "        df.loc[len(df.index)] = [f1['f1'], precision['precision'], recall['recall'], tn, fp, fn, tp, predictions]\n",
    "        df.to_csv('results.csv') \n",
    "        # ***** update an external results .csv file ***** # \n",
    "\n",
    "        return f1\n",
    "    \n",
    "    # define test and train splits\n",
    "    train_dataset = tokenized_datasets[\"train\"]\n",
    "    test_dataset = tokenized_datasets[\"test\"]\n",
    "\n",
    "    # creates and trains a Trainer object\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # save model\n",
    "    trainer.save_model(output_dir)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff95807f-037e-46e5-bb88-bbd2673a02f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training args and model\n",
    "training_args = TrainingArguments(output_dir=output_dir, \n",
    "                                  evaluation_strategy=\"epoch\", \n",
    "                                  num_train_epochs=10, \n",
    "                                  learning_rate=1e-5, \n",
    "                                  per_device_train_batch_size=4,\n",
    "                                  per_device_eval_batch_size=4,\n",
    "                                  # per_device_eval_batch_size=16,\n",
    "                                  logging_strategy = 'epoch',\n",
    "                                  # logging_first_step = True,\n",
    "                                  save_strategy = 'no',\n",
    "                                  # save_strategy = 'epoch',\n",
    "                                  # save_total_limit = 1,\n",
    "                                  # load_best_model_at_end = True,\n",
    "                                  # metric_for_best_model = 'f1'\n",
    "                                 )\n",
    "\n",
    "model_name = 'bert-base-multilingual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d87e88c-b3ec-4a22-b007-24b78a040002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tune on separate train-test files\n",
    "trainfile_prefix = 'train_'\n",
    "testfile_prefix = 'test_'\n",
    "\n",
    "num_tests = 5\n",
    "\n",
    "for x in range(0, num_tests):\n",
    "    train_path = trainfile_prefix + str(x) + '.csv'\n",
    "    test_path = testfile_prefix + str(x) + '.csv'\n",
    "    model_output_dir = 'output' # creates directory for saved models\n",
    "    \n",
    "    model = run_trainer(train_path, \n",
    "                    test_path, \n",
    "                    model_output_dir \n",
    "                    # logger\n",
    "                   )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "euphemisms",
   "language": "python",
   "name": "euphemisms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
