{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc1090a7-22d6-4b16-92b7-73c8296ba819",
   "metadata": {},
   "source": [
    "# Multilingual Data Processing for SequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86373517-cfba-42e2-b17a-62a5385e9998",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset-specific Prep and Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "795610d5-5fe8-44c3-94c1-4c88e243710a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"tinkle\" has 2 euphemistic examples and 0 non-euphemistic examples. Taking 2 and 0 for the final dataset.\n",
      "\"undocumented immigrant\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"venereal disease\" has 6 euphemistic examples and 0 non-euphemistic examples. Taking 6 and 0 for the final dataset.\n",
      "\"sex worker\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"mentally disabled\" has 11 euphemistic examples and 0 non-euphemistic examples. Taking 11 and 0 for the final dataset.\n",
      "\"correctional facility\" has 18 euphemistic examples and 0 non-euphemistic examples. Taking 18 and 0 for the final dataset.\n",
      "\"freedom fighter\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"detainee\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"comfort women\" has 3 euphemistic examples and 0 non-euphemistic examples. Taking 3 and 0 for the final dataset.\n",
      "\"psychiatric hospital\" has 11 euphemistic examples and 0 non-euphemistic examples. Taking 11 and 0 for the final dataset.\n",
      "\"ethnic cleansing\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"lose [pro] lunch\" has 4 euphemistic examples and 0 non-euphemistic examples. Taking 4 and 0 for the final dataset.\n",
      "\"enhanced interrogation techniques\" has 6 euphemistic examples and 0 non-euphemistic examples. Taking 6 and 0 for the final dataset.\n",
      "\"mistruth\" has 4 euphemistic examples and 0 non-euphemistic examples. Taking 4 and 0 for the final dataset.\n",
      "\"elderly\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"armed conflict\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"drinking problem\" has 7 euphemistic examples and 0 non-euphemistic examples. Taking 7 and 0 for the final dataset.\n",
      "\"deceased\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"pro-life\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"income inequality\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"rear end\" has 10 euphemistic examples and 0 non-euphemistic examples. Taking 10 and 0 for the final dataset.\n",
      "\"lavatory\" has 7 euphemistic examples and 0 non-euphemistic examples. Taking 7 and 0 for the final dataset.\n",
      "\"birds and the bees\" has 7 euphemistic examples and 0 non-euphemistic examples. Taking 7 and 0 for the final dataset.\n",
      "\"inner city\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"developed/ing country\" has 19 euphemistic examples and 0 non-euphemistic examples. Taking 19 and 0 for the final dataset.\n",
      "\"substance abuse\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"global south\" has 8 euphemistic examples and 0 non-euphemistic examples. Taking 8 and 0 for the final dataset.\n",
      "\"underprivileged\" has 11 euphemistic examples and 0 non-euphemistic examples. Taking 11 and 0 for the final dataset.\n",
      "\"inebriated\" has 16 euphemistic examples and 0 non-euphemistic examples. Taking 16 and 0 for the final dataset.\n",
      "\"homemaker\" has 19 euphemistic examples and 0 non-euphemistic examples. Taking 19 and 0 for the final dataset.\n",
      "\"capital punishment\" has 19 euphemistic examples and 0 non-euphemistic examples. Taking 19 and 0 for the final dataset.\n",
      "\"differently-abled\" has 2 euphemistic examples and 0 non-euphemistic examples. Taking 2 and 0 for the final dataset.\n",
      "\"indigent\" has 18 euphemistic examples and 0 non-euphemistic examples. Taking 18 and 0 for the final dataset.\n",
      "\"detention camp\" has 10 euphemistic examples and 0 non-euphemistic examples. Taking 10 and 0 for the final dataset.\n",
      "\"economical with the truth\" has 1 euphemistic examples and 0 non-euphemistic examples. Taking 1 and 0 for the final dataset.\n",
      "\"pass gas\" has 1 euphemistic examples and 0 non-euphemistic examples. Taking 1 and 0 for the final dataset.\n",
      "\"dearly departed\" has 3 euphemistic examples and 0 non-euphemistic examples. Taking 3 and 0 for the final dataset.\n",
      "\"pregnancy termination\" has 4 euphemistic examples and 0 non-euphemistic examples. Taking 4 and 0 for the final dataset.\n",
      "\"senior citizen\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"substance abuser\" has 11 euphemistic examples and 0 non-euphemistic examples. Taking 11 and 0 for the final dataset.\n",
      "\"undocumented workers\" has 13 euphemistic examples and 0 non-euphemistic examples. Taking 13 and 0 for the final dataset.\n",
      "\"pre-owned\" has 7 euphemistic examples and 0 non-euphemistic examples. Taking 7 and 0 for the final dataset.\n",
      "\"sanitation worker\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"street person\" has 3 euphemistic examples and 0 non-euphemistic examples. Taking 3 and 0 for the final dataset.\n",
      "\"full figured\" has 1 euphemistic examples and 0 non-euphemistic examples. Taking 1 and 0 for the final dataset.\n",
      "\"latrine\" has 3 euphemistic examples and 0 non-euphemistic examples. Taking 3 and 0 for the final dataset.\n",
      "\"plus-sized\" has 2 euphemistic examples and 0 non-euphemistic examples. Taking 2 and 0 for the final dataset.\n",
      "\"physically challenged\" has 1 euphemistic examples and 0 non-euphemistic examples. Taking 1 and 0 for the final dataset.\n",
      "\"developmentally disabled\" has 2 euphemistic examples and 0 non-euphemistic examples. Taking 2 and 0 for the final dataset.\n",
      "\"custodians\" has 2 euphemistic examples and 0 non-euphemistic examples. Taking 2 and 0 for the final dataset.\n",
      "\"same sex\" has 4 euphemistic examples and 0 non-euphemistic examples. Taking 4 and 0 for the final dataset.\n",
      "\"able-bodied\" has 7 euphemistic examples and 0 non-euphemistic examples. Taking 7 and 0 for the final dataset.\n",
      "\"hearing impaired\" has 2 euphemistic examples and 0 non-euphemistic examples. Taking 2 and 0 for the final dataset.\n",
      "\"under the weather\" has 1 euphemistic examples and 0 non-euphemistic examples. Taking 1 and 0 for the final dataset.\n",
      "\"people/persons of color\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"adult beverage\" has 1 euphemistic examples and 0 non-euphemistic examples. Taking 1 and 0 for the final dataset.\n",
      "\"broken home\" has 1 euphemistic examples and 0 non-euphemistic examples. Taking 1 and 0 for the final dataset.\n",
      "\"fatality\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"pro-choice\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"targeted killing\" has 11 euphemistic examples and 0 non-euphemistic examples. Taking 11 and 0 for the final dataset.\n",
      "\"low-income\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"less fortunate\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"advanced age\" has 19 euphemistic examples and 0 non-euphemistic examples. Taking 19 and 0 for the final dataset.\n",
      "\"mentally challenged\" has 17 euphemistic examples and 0 non-euphemistic examples. Taking 17 and 0 for the final dataset.\n",
      "\"droppings\" has 18 euphemistic examples and 0 non-euphemistic examples. Taking 18 and 0 for the final dataset.\n",
      "\"portly\" has 7 euphemistic examples and 0 non-euphemistic examples. Taking 7 and 0 for the final dataset.\n",
      "\"negative cash flow\" has 3 euphemistic examples and 0 non-euphemistic examples. Taking 3 and 0 for the final dataset.\n",
      "\"golden years\" has 17 euphemistic examples and 0 non-euphemistic examples. Taking 17 and 0 for the final dataset.\n",
      "\"time of the month\" has 5 euphemistic examples and 0 non-euphemistic examples. Taking 5 and 0 for the final dataset.\n",
      "\"make love\" has 11 euphemistic examples and 0 non-euphemistic examples. Taking 11 and 0 for the final dataset.\n",
      "\"running behind\" has 1 euphemistic examples and 0 non-euphemistic examples. Taking 1 and 0 for the final dataset.\n",
      "\"let go of\" has 5 euphemistic examples and 5 non-euphemistic examples. Taking 5 and 5 for the final dataset.\n",
      "\"let [pro] go\" has 7 euphemistic examples and 7 non-euphemistic examples. Taking 7 and 7 for the final dataset.\n",
      "\"perish\" has 20 euphemistic examples and 20 non-euphemistic examples. Taking 20 and 20 for the final dataset.\n",
      "\"pass on\" has 6 euphemistic examples and 6 non-euphemistic examples. Taking 6 and 6 for the final dataset.\n",
      "\"pass away\" has 18 euphemistic examples and 18 non-euphemistic examples. Taking 18 and 18 for the final dataset.\n",
      "\"neutralize\" has 8 euphemistic examples and 8 non-euphemistic examples. Taking 8 and 8 for the final dataset.\n",
      "\"overweight\" has 16 euphemistic examples and 22 non-euphemistic examples. Taking 16 and 22 for the final dataset.\n",
      "\"aging\" has 29 euphemistic examples and 31 non-euphemistic examples. Taking 29 and 31 for the final dataset.\n",
      "\"chest\" has 7 euphemistic examples and 13 non-euphemistic examples. Taking 7 and 13 for the final dataset.\n",
      "\"demise\" has 28 euphemistic examples and 28 non-euphemistic examples. Taking 28 and 28 for the final dataset.\n",
      "\"slim\" has 10 euphemistic examples and 14 non-euphemistic examples. Taking 10 and 14 for the final dataset.\n",
      "\"dismissed\" has 13 euphemistic examples and 13 non-euphemistic examples. Taking 13 and 13 for the final dataset.\n",
      "\"sober\" has 11 euphemistic examples and 11 non-euphemistic examples. Taking 11 and 11 for the final dataset.\n",
      "\"collateral damage\" has 26 euphemistic examples and 26 non-euphemistic examples. Taking 26 and 26 for the final dataset.\n",
      "\"deprived\" has 2 euphemistic examples and 2 non-euphemistic examples. Taking 2 and 2 for the final dataset.\n",
      "\"plump\" has 10 euphemistic examples and 10 non-euphemistic examples. Taking 10 and 10 for the final dataset.\n",
      "\"same-sex\" has 7 euphemistic examples and 9 non-euphemistic examples. Taking 7 and 9 for the final dataset.\n",
      "\"go all the way\" has 5 euphemistic examples and 5 non-euphemistic examples. Taking 5 and 5 for the final dataset.\n",
      "\"stout\" has 6 euphemistic examples and 6 non-euphemistic examples. Taking 6 and 6 for the final dataset.\n",
      "\"disabled\" has 29 euphemistic examples and 31 non-euphemistic examples. Taking 29 and 31 for the final dataset.\n",
      "\"special needs\" has 19 euphemistic examples and 7 non-euphemistic examples. Taking 19 and 7 for the final dataset.\n",
      "\"disadvantaged\" has 14 euphemistic examples and 14 non-euphemistic examples. Taking 14 and 14 for the final dataset.\n",
      "\"underdeveloped\" has 13 euphemistic examples and 13 non-euphemistic examples. Taking 13 and 13 for the final dataset.\n",
      "\"invalid\" has 3 euphemistic examples and 3 non-euphemistic examples. Taking 3 and 3 for the final dataset.\n",
      "\"mixed up\" has 11 euphemistic examples and 11 non-euphemistic examples. Taking 11 and 11 for the final dataset.\n",
      "\"well off\" has 11 euphemistic examples and 11 non-euphemistic examples. Taking 11 and 11 for the final dataset.\n",
      "\"economical\" has 13 euphemistic examples and 15 non-euphemistic examples. Taking 13 and 15 for the final dataset.\n",
      "\"over the hill\" has 6 euphemistic examples and 6 non-euphemistic examples. Taking 6 and 6 for the final dataset.\n",
      "\"intoxicated\" has 16 euphemistic examples and 16 non-euphemistic examples. Taking 16 and 16 for the final dataset.\n",
      "\"regime change\" has 11 euphemistic examples and 3 non-euphemistic examples. Taking 11 and 3 for the final dataset.\n",
      "\"exterminate\" has 16 euphemistic examples and 2 non-euphemistic examples. Taking 16 and 2 for the final dataset.\n",
      "\"a certain age\" has 12 euphemistic examples and 9 non-euphemistic examples. Taking 12 and 9 for the final dataset.\n",
      "\"custodian\" has 6 euphemistic examples and 6 non-euphemistic examples. Taking 6 and 6 for the final dataset.\n",
      "\"put to sleep\" has 7 euphemistic examples and 3 non-euphemistic examples. Taking 7 and 3 for the final dataset.\n",
      "\"between jobs\" has 7 euphemistic examples and 7 non-euphemistic examples. Taking 7 and 7 for the final dataset.\n",
      "\"long sleep\" has 1 euphemistic examples and 1 non-euphemistic examples. Taking 1 and 1 for the final dataset.\n",
      "\"getting clean\" has 2 euphemistic examples and 2 non-euphemistic examples. Taking 2 and 2 for the final dataset.\n",
      "\"downsize\" has 2 euphemistic examples and 2 non-euphemistic examples. Taking 2 and 2 for the final dataset.\n",
      "\"expecting\" has 23 euphemistic examples and 23 non-euphemistic examples. Taking 23 and 23 for the final dataset.\n",
      "\"lay off\" has 18 euphemistic examples and 18 non-euphemistic examples. Taking 18 and 18 for the final dataset.\n",
      "\"go to heaven\" has 2 euphemistic examples and 2 non-euphemistic examples. Taking 2 and 2 for the final dataset.\n",
      "\"accident\" has 25 euphemistic examples and 7 non-euphemistic examples. Taking 25 and 7 for the final dataset.\n",
      "\"gluteus maximus\" has 1 euphemistic examples and 1 non-euphemistic examples. Taking 1 and 1 for the final dataset.\n",
      "\"outlived [pro] usefulness\" has 2 euphemistic examples and 2 non-euphemistic examples. Taking 2 and 2 for the final dataset.\n",
      "\"got clean\" has 1 euphemistic examples and 1 non-euphemistic examples. Taking 1 and 1 for the final dataset.\n",
      "\"oldest profession\" has 1 euphemistic examples and 1 non-euphemistic examples. Taking 1 and 1 for the final dataset.\n",
      "\"late\" has 30 euphemistic examples and 30 non-euphemistic examples. Taking 30 and 30 for the final dataset.\n",
      "\"experienced\" has 2 euphemistic examples and 4 non-euphemistic examples. Taking 2 and 4 for the final dataset.\n",
      "\"outspoken\" has 3 euphemistic examples and 3 non-euphemistic examples. Taking 3 and 3 for the final dataset.\n",
      "\"wealthy\" has 7 euphemistic examples and 3 non-euphemistic examples. Taking 7 and 3 for the final dataset.\n",
      "\"troubled\" has 15 euphemistic examples and 15 non-euphemistic examples. Taking 15 and 15 for the final dataset.\n",
      "\"seeing someone/each other\" has 2 euphemistic examples and 2 non-euphemistic examples. Taking 2 and 2 for the final dataset.\n",
      "\"seasoned\" has 2 euphemistic examples and 2 non-euphemistic examples. Taking 2 and 2 for the final dataset.\n",
      "\"sleep with\" has 6 euphemistic examples and 6 non-euphemistic examples. Taking 6 and 6 for the final dataset.\n",
      "\"sleep around\" has 1 euphemistic examples and 1 non-euphemistic examples. Taking 1 and 1 for the final dataset.\n",
      "\"with child\" has 2 euphemistic examples and 2 non-euphemistic examples. Taking 2 and 2 for the final dataset.\n",
      "\"weed\" has 30 euphemistic examples and 30 non-euphemistic examples. Taking 30 and 30 for the final dataset.\n",
      "Max number of examples taken per label: 40\n",
      "Original size of corpus: 1952\n",
      "Size of sampled corpus: 1952\n",
      "Sample corpus contains 1383 euphemistic examples and 569 non-euphemistic examples\n",
      "Saving corpus to \"Multilingual_Data/english_sampled_v0.csv\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# prep\n",
    "df = pd.read_csv('Multilingual_Data/english_original.csv', index_col=0, encoding='utf-8') # file path of the corpus\n",
    "df = df.reset_index(drop=True)\n",
    "# df = df.loc[df['Category'].isin([0, 1])] # has some no-label rows\n",
    "df = df.dropna()\n",
    "# df = df.astype({'Category':'int'})\n",
    "\n",
    "sampled_corpus = pd.DataFrame() # the sampled examples\n",
    "PET_col_name = 'type' # name of the column indicating the PET\n",
    "label_col_name = 'is_euph' # name of the column indicating the label \n",
    "max_num_ex = 40\n",
    "\n",
    "for PET in df[PET_col_name].unique():\n",
    "    # sample from euphemistic examples\n",
    "    euph_ex = df.loc[(df[PET_col_name]==PET) & (df[label_col_name]==1)]\n",
    "    num_euph_sample = min(max_num_ex, len(euph_ex)) # choose up to the max num of euphemistic examples\n",
    "    euph_sample = euph_ex.sample(n=num_euph_sample)\n",
    "    sampled_corpus = pd.concat([sampled_corpus, euph_sample])\n",
    "    # sample from non-euphemistic examples\n",
    "    noneuph_ex = df.loc[(df[PET_col_name]==PET) & (df[label_col_name]==0)] # choose up to the max num, or num of euphemistic examples\n",
    "    num_noneuph_sample = min(max_num_ex, len(noneuph_ex))\n",
    "    noneuph_sample = noneuph_ex.sample(n=num_noneuph_sample)\n",
    "    sampled_corpus = pd.concat([sampled_corpus, noneuph_sample])\n",
    "    # print out stats per PET\n",
    "    print(\"\\\"{}\\\" has {} euphemistic examples and {} non-euphemistic examples. Taking {} and {} for the final dataset.\".format(PET, len(euph_ex), len(noneuph_ex), num_euph_sample, num_noneuph_sample))\n",
    "\n",
    "print(\"Max number of examples taken per label:\", max_num_ex)\n",
    "print(\"Original size of corpus:\", len(df))\n",
    "print(\"Size of sampled corpus:\", len(sampled_corpus))\n",
    "euph_examples = sampled_corpus.loc[sampled_corpus[label_col_name]==1]\n",
    "noneuph_examples = sampled_corpus.loc[sampled_corpus[label_col_name]==0]\n",
    "print(\"Sample corpus contains {} euphemistic examples and {} non-euphemistic examples\".format(len(euph_examples), len(noneuph_examples)))\n",
    "\n",
    "# save the sampled corpus\n",
    "sampled_corpus = sampled_corpus.reset_index(drop=True)\n",
    "dest = \"Multilingual_Data/english_sampled_v0.csv\"\n",
    "print(\"Saving corpus to \\\"{}\\\"\".format(dest))\n",
    "sampled_corpus.to_csv(dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329f4079-2c3e-4463-bee8-591634c2fb54",
   "metadata": {},
   "source": [
    "### Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebe6a366-6bed-4d7e-97cd-cf1a4986f781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"下身\" has 7 euphemistic examples and 122 non-euphemistic examples. Taking 7 and 40 for the final dataset.\n",
      "\"不在了\" has 12 euphemistic examples and 14 non-euphemistic examples. Taking 12 and 14 for the final dataset.\n",
      "\"云雨\" has 1 euphemistic examples and 1 non-euphemistic examples. Taking 1 and 1 for the final dataset.\n",
      "\"作古\" has 3 euphemistic examples and 2 non-euphemistic examples. Taking 3 and 2 for the final dataset.\n",
      "\"升天\" has 4 euphemistic examples and 6 non-euphemistic examples. Taking 4 and 6 for the final dataset.\n",
      "\"同志\" has 16 euphemistic examples and 786 non-euphemistic examples. Taking 16 and 40 for the final dataset.\n",
      "\"同房\" has 17 euphemistic examples and 1 non-euphemistic examples. Taking 17 and 1 for the final dataset.\n",
      "\"大号\" has 7 euphemistic examples and 144 non-euphemistic examples. Taking 7 and 40 for the final dataset.\n",
      "\"大清洗\" has 2 euphemistic examples and 1 non-euphemistic examples. Taking 2 and 1 for the final dataset.\n",
      "\"夫妻生活\" has 19 euphemistic examples and 3 non-euphemistic examples. Taking 19 and 3 for the final dataset.\n",
      "\"姨妈\" has 27 euphemistic examples and 11 non-euphemistic examples. Taking 27 and 11 for the final dataset.\n",
      "\"小姐\" has 36 euphemistic examples and 709 non-euphemistic examples. Taking 36 and 40 for the final dataset.\n",
      "\"小解\" has 1 euphemistic examples and 2 non-euphemistic examples. Taking 1 and 2 for the final dataset.\n",
      "\"干柴烈火\" has 1 euphemistic examples and 3 non-euphemistic examples. Taking 1 and 3 for the final dataset.\n",
      "\"挂了\" has 4 euphemistic examples and 38 non-euphemistic examples. Taking 4 and 38 for the final dataset.\n",
      "\"有喜\" has 12 euphemistic examples and 12 non-euphemistic examples. Taking 12 and 12 for the final dataset.\n",
      "\"牺牲\" has 138 euphemistic examples and 172 non-euphemistic examples. Taking 40 and 40 for the final dataset.\n",
      "\"胸部\" has 139 euphemistic examples and 99 non-euphemistic examples. Taking 40 and 40 for the final dataset.\n",
      "\"自慰\" has 3 euphemistic examples and 1 non-euphemistic examples. Taking 3 and 1 for the final dataset.\n",
      "\"走了\" has 13 euphemistic examples and 346 non-euphemistic examples. Taking 13 and 40 for the final dataset.\n",
      "\"龙阳\" has 0 euphemistic examples and 3 non-euphemistic examples. Taking 0 and 3 for the final dataset.\n",
      "\"下岗\" has 36 euphemistic examples and 0 non-euphemistic examples. Taking 36 and 0 for the final dataset.\n",
      "\"仙逝\" has 4 euphemistic examples and 0 non-euphemistic examples. Taking 4 and 0 for the final dataset.\n",
      "\"低收入\" has 51 euphemistic examples and 0 non-euphemistic examples. Taking 40 and 0 for the final dataset.\n",
      "\"例假\" has 10 euphemistic examples and 0 non-euphemistic examples. Taking 10 and 0 for the final dataset.\n",
      "\"保留态度\" has 4 euphemistic examples and 0 non-euphemistic examples. Taking 4 and 0 for the final dataset.\n",
      "\"保留意见\" has 11 euphemistic examples and 0 non-euphemistic examples. Taking 11 and 0 for the final dataset.\n",
      "\"卫生间\" has 184 euphemistic examples and 0 non-euphemistic examples. Taking 40 and 0 for the final dataset.\n",
      "\"去世\" has 293 euphemistic examples and 0 non-euphemistic examples. Taking 40 and 0 for the final dataset.\n",
      "\"发福\" has 46 euphemistic examples and 0 non-euphemistic examples. Taking 40 and 0 for the final dataset.\n",
      "\"圆寂\" has 4 euphemistic examples and 0 non-euphemistic examples. Taking 4 and 0 for the final dataset.\n",
      "\"圆房\" has 2 euphemistic examples and 0 non-euphemistic examples. Taking 2 and 0 for the final dataset.\n",
      "\"夭折\" has 27 euphemistic examples and 0 non-euphemistic examples. Taking 27 and 0 for the final dataset.\n",
      "\"失明\" has 46 euphemistic examples and 0 non-euphemistic examples. Taking 40 and 0 for the final dataset.\n",
      "\"失聪\" has 7 euphemistic examples and 0 non-euphemistic examples. Taking 7 and 0 for the final dataset.\n",
      "\"失足妇女\" has 1 euphemistic examples and 0 non-euphemistic examples. Taking 1 and 0 for the final dataset.\n",
      "\"如厕\" has 14 euphemistic examples and 0 non-euphemistic examples. Taking 14 and 0 for the final dataset.\n",
      "\"家庭主妇\" has 22 euphemistic examples and 0 non-euphemistic examples. Taking 22 and 0 for the final dataset.\n",
      "\"富态\" has 2 euphemistic examples and 0 non-euphemistic examples. Taking 2 and 0 for the final dataset.\n",
      "\"就义\" has 1 euphemistic examples and 0 non-euphemistic examples. Taking 1 and 0 for the final dataset.\n",
      "\"往生\" has 4 euphemistic examples and 0 non-euphemistic examples. Taking 4 and 0 for the final dataset.\n",
      "\"待业\" has 9 euphemistic examples and 0 non-euphemistic examples. Taking 9 and 0 for the final dataset.\n",
      "\"性侵\" has 43 euphemistic examples and 0 non-euphemistic examples. Taking 40 and 0 for the final dataset.\n",
      "\"性工作者\" has 4 euphemistic examples and 0 non-euphemistic examples. Taking 4 and 0 for the final dataset.\n",
      "\"慰安妇\" has 30 euphemistic examples and 0 non-euphemistic examples. Taking 30 and 0 for the final dataset.\n",
      "\"房事\" has 24 euphemistic examples and 0 non-euphemistic examples. Taking 24 and 0 for the final dataset.\n",
      "\"捐躯\" has 2 euphemistic examples and 0 non-euphemistic examples. Taking 2 and 0 for the final dataset.\n",
      "\"敏感词\" has 2 euphemistic examples and 0 non-euphemistic examples. Taking 2 and 0 for the final dataset.\n",
      "\"方便\" has 3 euphemistic examples and 2240 non-euphemistic examples. Taking 3 and 40 for the final dataset.\n",
      "\"智力缺陷\" has 1 euphemistic examples and 0 non-euphemistic examples. Taking 1 and 0 for the final dataset.\n",
      "\"殉职\" has 3 euphemistic examples and 0 non-euphemistic examples. Taking 3 and 0 for the final dataset.\n",
      "\"永别\" has 7 euphemistic examples and 0 non-euphemistic examples. Taking 7 and 0 for the final dataset.\n",
      "\"洗手间\" has 44 euphemistic examples and 0 non-euphemistic examples. Taking 40 and 0 for the final dataset.\n",
      "\"滑铁卢\" has 12 euphemistic examples and 0 non-euphemistic examples. Taking 12 and 0 for the final dataset.\n",
      "\"特殊人群\" has 20 euphemistic examples and 0 non-euphemistic examples. Taking 20 and 0 for the final dataset.\n",
      "\"环卫工人\" has 87 euphemistic examples and 0 non-euphemistic examples. Taking 40 and 0 for the final dataset.\n",
      "\"生理期\" has 18 euphemistic examples and 0 non-euphemistic examples. Taking 18 and 0 for the final dataset.\n",
      "\"盥洗室\" has 2 euphemistic examples and 0 non-euphemistic examples. Taking 2 and 0 for the final dataset.\n",
      "\"离世\" has 65 euphemistic examples and 0 non-euphemistic examples. Taking 40 and 0 for the final dataset.\n",
      "\"私处\" has 22 euphemistic examples and 0 non-euphemistic examples. Taking 22 and 0 for the final dataset.\n",
      "\"红灯区\" has 5 euphemistic examples and 0 non-euphemistic examples. Taking 5 and 0 for the final dataset.\n",
      "\"结构优化\" has 42 euphemistic examples and 0 non-euphemistic examples. Taking 40 and 0 for the final dataset.\n",
      "\"表示遗憾\" has 16 euphemistic examples and 0 non-euphemistic examples. Taking 16 and 0 for the final dataset.\n",
      "\"解手\" has 2 euphemistic examples and 0 non-euphemistic examples. Taking 2 and 0 for the final dataset.\n",
      "\"负增长\" has 50 euphemistic examples and 0 non-euphemistic examples. Taking 40 and 0 for the final dataset.\n",
      "\"身故\" has 9 euphemistic examples and 0 non-euphemistic examples. Taking 9 and 0 for the final dataset.\n",
      "\"辞退\" has 35 euphemistic examples and 0 non-euphemistic examples. Taking 35 and 0 for the final dataset.\n",
      "\"逝世\" has 82 euphemistic examples and 0 non-euphemistic examples. Taking 40 and 0 for the final dataset.\n",
      "\"长眠\" has 10 euphemistic examples and 0 non-euphemistic examples. Taking 10 and 0 for the final dataset.\n",
      "\"驾崩\" has 4 euphemistic examples and 0 non-euphemistic examples. Taking 4 and 0 for the final dataset.\n",
      "Max number of examples taken per label: 40\n",
      "Original size of corpus: 6600\n",
      "Size of sampled corpus: 1552\n",
      "Sample corpus contains 1134 euphemistic examples and 418 non-euphemistic examples\n",
      "Saving corpus to \"Multilingual_Data/chinese_sampled_v1.csv\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# prep\n",
    "df = pd.read_csv('Multilingual_Data/chinese_original.csv', index_col=0, encoding='utf-8') # file path of the corpus\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.loc[df['Category'].isin([0, 1])] # has some no-label rows\n",
    "df = df.dropna()\n",
    "df = df.astype({'Category':'int'})\n",
    "\n",
    "sampled_corpus = pd.DataFrame() # the sampled examples\n",
    "PET_col_name = 'PET' # name of the column indicating the PET\n",
    "label_col_name = 'Category' # name of the column indicating the label \n",
    "max_num_ex = 40\n",
    "\n",
    "for PET in df[PET_col_name].unique():\n",
    "    # sample from euphemistic examples\n",
    "    euph_ex = df.loc[(df[PET_col_name]==PET) & (df[label_col_name]==1)]\n",
    "    num_euph_sample = min(max_num_ex, len(euph_ex)) # choose up to the max num of euphemistic examples\n",
    "    euph_sample = euph_ex.sample(n=num_euph_sample)\n",
    "    sampled_corpus = pd.concat([sampled_corpus, euph_sample])\n",
    "    # sample from non-euphemistic examples\n",
    "    noneuph_ex = df.loc[(df[PET_col_name]==PET) & (df[label_col_name]==0)] # choose up to the max num, or num of euphemistic examples\n",
    "    num_noneuph_sample = min(max_num_ex, len(noneuph_ex))\n",
    "    noneuph_sample = noneuph_ex.sample(n=num_noneuph_sample)\n",
    "    sampled_corpus = pd.concat([sampled_corpus, noneuph_sample])\n",
    "    # print out stats per PET\n",
    "    print(\"\\\"{}\\\" has {} euphemistic examples and {} non-euphemistic examples. Taking {} and {} for the final dataset.\".format(PET, len(euph_ex), len(noneuph_ex), num_euph_sample, num_noneuph_sample))\n",
    "\n",
    "print(\"Max number of examples taken per label:\", max_num_ex)\n",
    "print(\"Original size of corpus:\", len(df))\n",
    "print(\"Size of sampled corpus:\", len(sampled_corpus))\n",
    "euph_examples = sampled_corpus.loc[sampled_corpus[label_col_name]==1]\n",
    "noneuph_examples = sampled_corpus.loc[sampled_corpus[label_col_name]==0]\n",
    "print(\"Sample corpus contains {} euphemistic examples and {} non-euphemistic examples\".format(len(euph_examples), len(noneuph_examples)))\n",
    "\n",
    "# save the sampled corpus\n",
    "sampled_corpus = sampled_corpus.reset_index(drop=True)\n",
    "dest = \"Multilingual_Data/chinese_sampled_v1.csv\"\n",
    "print(\"Saving corpus to \\\"{}\\\"\".format(dest))\n",
    "sampled_corpus.to_csv(dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9134aacb-988b-4b3d-87da-c1b58d5068c7",
   "metadata": {},
   "source": [
    "### Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "019aecda-4d1b-498a-ad2f-a7ca7b0de721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of examples taken per label: 40\n",
      "Original size of corpus: 1000\n",
      "Size of sampled corpus: 961\n",
      "Sample corpus contains 564 euphemistic examples and 397 non-euphemistic examples\n",
      "Saving corpus to \"Multilingual_Data/spanish_sampled_v0.csv\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# prep\n",
    "df = pd.read_csv('Multilingual_Data/spanish_original.csv', index_col=0, encoding='utf-8')\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "sampled_corpus = pd.DataFrame() # the sampled examples\n",
    "PET_col_name = 'Palabra clave' # name of the column indicating the PET\n",
    "label_col_name = 'Es Eufemistico' # name of the column indicating the label \n",
    "max_num_ex = 40\n",
    "\n",
    "for PET in df[PET_col_name].unique():\n",
    "    # sample from euphemistic examples\n",
    "    euph_ex = df.loc[(df[PET_col_name]==PET) & (df[label_col_name]==1)]\n",
    "    num_euph_sample = min(max_num_ex, len(euph_ex)) # choose up to the max num of euphemistic examples\n",
    "    euph_sample = euph_ex.sample(n=num_euph_sample)\n",
    "    sampled_corpus = pd.concat([sampled_corpus, euph_sample])\n",
    "    # sample from non-euphemistic examples\n",
    "    noneuph_ex = df.loc[(df[PET_col_name]==PET) & (df[label_col_name]==0)] # choose up to the max num, or num of euphemistic examples\n",
    "    num_noneuph_sample = min(max_num_ex, len(noneuph_ex))\n",
    "    noneuph_sample = noneuph_ex.sample(n=num_noneuph_sample)\n",
    "    sampled_corpus = pd.concat([sampled_corpus, noneuph_sample])\n",
    "    # print out stats per PET\n",
    "    # print(\"\\\"{}\\\" has {} euphemistic examples and {} non-euphemistic examples. Taking {} and {} for the final dataset.\".format(PET, len(euph_ex), len(noneuph_ex), num_euph_sample, num_noneuph_sample))\n",
    "\n",
    "print(\"Max number of examples taken per label:\", max_num_ex)\n",
    "print(\"Original size of corpus:\", len(df))\n",
    "print(\"Size of sampled corpus:\", len(sampled_corpus))\n",
    "euph_examples = sampled_corpus.loc[sampled_corpus[label_col_name]==1]\n",
    "noneuph_examples = sampled_corpus.loc[sampled_corpus[label_col_name]==0]\n",
    "print(\"Sample corpus contains {} euphemistic examples and {} non-euphemistic examples\".format(len(euph_examples), len(noneuph_examples)))\n",
    "\n",
    "# save the sampled corpus\n",
    "sampled_corpus = sampled_corpus.reset_index(drop=True)\n",
    "dest = \"Multilingual_Data/spanish_sampled_v0.csv\"\n",
    "print(\"Saving corpus to \\\"{}\\\"\".format(dest))\n",
    "sampled_corpus.to_csv(dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63715858-4997-4f44-8bf4-8d7e0ca5bd30",
   "metadata": {},
   "source": [
    "### Yoruba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7831edf-c95f-4ddc-8e52-57a2b241ebef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of examples taken per label: 40\n",
      "Original size of corpus: 2144\n",
      "Size of sampled corpus: 1942\n",
      "Sample corpus contains 1281 euphemistic examples and 661 non-euphemistic examples\n",
      "Saving corpus to \"Multilingual_Data/yoruba_sampled_v1.1.csv\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# prep\n",
    "df = pd.read_csv(\"Multilingual_Data/yoruba_original.csv\")\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df = df.loc[df['Rating'].isin([0, 1])] # has some no-label rows\n",
    "df = df.reset_index(drop=True)\n",
    "# df = df.dropna()\n",
    "df = df.astype({'Rating':'int'})\n",
    "\n",
    "sampled_corpus = pd.DataFrame() # the sampled examples\n",
    "PET_col_name = 'Euphemisms'\n",
    "label_col_name = 'Rating'\n",
    "max_num_ex = 40\n",
    "\n",
    "for PET in df[PET_col_name].unique():\n",
    "    # sample from euphemistic examples\n",
    "    euph_ex = df.loc[(df[PET_col_name]==PET) & (df[label_col_name]==1)]\n",
    "    num_euph_sample = min(max_num_ex, len(euph_ex)) # choose up to the max num of euphemistic examples\n",
    "    euph_sample = euph_ex.sample(n=num_euph_sample)\n",
    "    sampled_corpus = pd.concat([sampled_corpus, euph_sample])\n",
    "    # sample from non-euphemistic examples\n",
    "    noneuph_ex = df.loc[(df[PET_col_name]==PET) & (df[label_col_name]==0)] # choose up to the max num, or num of euphemistic examples\n",
    "    num_noneuph_sample = min(max_num_ex, len(noneuph_ex))\n",
    "    noneuph_sample = noneuph_ex.sample(n=num_noneuph_sample)\n",
    "    sampled_corpus = pd.concat([sampled_corpus, noneuph_sample])\n",
    "    # print out stats per PET\n",
    "    # print(\"\\\"{}\\\" has {} euphemistic examples and {} non-euphemistic examples. Taking {} and {} for the final dataset.\".format(PET, len(euph_ex), len(noneuph_ex), num_euph_sample, num_noneuph_sample))\n",
    "\n",
    "print(\"Max number of examples taken per label:\", max_num_ex)\n",
    "print(\"Original size of corpus:\", len(df))\n",
    "print(\"Size of sampled corpus:\", len(sampled_corpus))\n",
    "euph_examples = sampled_corpus.loc[sampled_corpus[label_col_name]==1]\n",
    "noneuph_examples = sampled_corpus.loc[sampled_corpus[label_col_name]==0]\n",
    "print(\"Sample corpus contains {} euphemistic examples and {} non-euphemistic examples\".format(len(euph_examples), len(noneuph_examples)))\n",
    "\n",
    "# save the sampled corpus\n",
    "sampled_corpus = sampled_corpus.reset_index(drop=True)\n",
    "dest = \"Multilingual_Data/yoruba_sampled_v1.1.csv\"\n",
    "print(\"Saving corpus to \\\"{}\\\"\".format(dest))\n",
    "sampled_corpus.to_csv(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e37dd2-81aa-450f-b227-2acda5d896d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD CODE to print out stats\n",
    "# num_euph_ex = 0 \n",
    "# num_noneuph_ex = 0\n",
    "\n",
    "# for PET in df[PET_col_name].unique():\n",
    "#     euph_ex = df.loc[(df[PET_col_name]==PET) & (df[label_col_name]==1)]\n",
    "#     num_euph_sample = min(max_num_ex, len(euph_ex)) # choose up to the max num of euphemistic examples\n",
    "#     num_euph_ex += num_euph_sample\n",
    "#     noneuph_ex = df.loc[(df[PET_col_name]==PET) & (df[label_col_name]==0)] # choose up to the max num, or num of euphemistic examples\n",
    "#     num_noneuph_sample = min(max_num_ex, len(noneuph_ex))\n",
    "#     num_noneuph_ex += num_noneuph_sample\n",
    "#     print(\"\\\"{}\\\" has {} euphemistic examples and {} non-euphemistic examples. Taking {} and {} for the final dataset.\".format(PET, len(euph_ex), len(noneuph_ex), num_euph_sample, num_noneuph_sample))\n",
    "    \n",
    "# print(num_euph_ex)\n",
    "# print(num_noneuph_ex)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad93bdb9-4ba0-4c82-832a-b820c54e54ab",
   "metadata": {},
   "source": [
    "## Format and Create Input Data for HuggingFace SequenceClassification\n",
    "Must have columns named 'text' and 'label'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88129752-f5b5-44dc-ac50-69e9e5f24e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a corpus with a 'text' column and 'label', return k folds\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "def get_k_fold_splits(corpus, k=5):\n",
    "    folds = []\n",
    "    skf = StratifiedKFold(n_splits=k)\n",
    "    split = skf.split(corpus, corpus.label)\n",
    "    for train_index, test_index in split:\n",
    "        train_df = corpus.iloc[train_index].sample(frac=1) # select training rows and shuffle them\n",
    "        test_df = corpus.iloc[test_index].sample(frac=1)\n",
    "        print(\"TRAIN: {} ({} 1s and {} 0s) | TEST: {} ({} 1s and {} 0s)\".format(len(train_df), len(train_df[train_df['label']==1]), len(train_df[train_df['label']==0]),\n",
    "                                                                               len(test_df), len(test_df[test_df['label']==1]), len(test_df[test_df['label']==0])))\n",
    "        folds.append((train_df,test_df))\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c972b74a-5ea1-437f-8a75-f3dac02c369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# specify source folders\n",
    "chinese_src = 'Multilingual_Data/chinese_sampled_v0.csv'\n",
    "spanish_src = 'Multilingual_Data/spanish_sampled_v0.csv'\n",
    "yoruba_src = 'Multilingual_Data/yoruba_sampled_v1.csv'\n",
    "english_src = \"Multilingual_Data/english_sampled_v0.csv\"\n",
    "# and destination folders; set K in the next chunk\n",
    "chinese_dest = 'Multilingual_Data/chinese-5_fold_v1'\n",
    "spanish_dest = 'Multilingual_Data/spanish-5_fold_v0'\n",
    "yoruba_dest = 'Multilingual_Data/yoruba-5_fold_v1.1'\n",
    "english_dest = 'Multilingual_Data/english-5-fold_v0'\n",
    "# if necessary, make directories\n",
    "# os.mkdir(chinese_dest)\n",
    "# os.mkdir(spanish_dest)\n",
    "# os.mkdir(yoruba_dest)\n",
    "# os.mkdir(english_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0e2cfe4-9244-4978-a536-e973d2ae5b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 1205 (876 1s and 329 0s) | TEST: 302 (219 1s and 83 0s)\n",
      "TRAIN: 1205 (876 1s and 329 0s) | TEST: 302 (219 1s and 83 0s)\n",
      "TRAIN: 1206 (876 1s and 330 0s) | TEST: 301 (219 1s and 82 0s)\n",
      "TRAIN: 1206 (876 1s and 330 0s) | TEST: 301 (219 1s and 82 0s)\n",
      "TRAIN: 1206 (876 1s and 330 0s) | TEST: 301 (219 1s and 82 0s)\n",
      "Tests output to Multilingual_Data/chinese-5_fold_v1\n"
     ]
    }
   ],
   "source": [
    "chinese_corpus = pd.read_csv(chinese_src, index_col=0)\n",
    "chinese_corpus = chinese_corpus[['edited_text', 'Category']]\n",
    "chinese_corpus = chinese_corpus.rename(columns={'edited_text':'text', 'Category':'label'})\n",
    "chinese_corpus = chinese_corpus.sample(frac=1)\n",
    "\n",
    "k_folds = get_k_fold_splits(chinese_corpus, k=5)\n",
    "for i in range(0, len(k_folds)): # for each fold, save the first element as the train df and the second as the test df\n",
    "    k_folds[i][0].to_csv(chinese_dest + '/hf_train_' + str(i) + '.csv', index=False)\n",
    "    k_folds[i][1].to_csv(chinese_dest + '/hf_test_' + str(i) + '.csv', index=False)\n",
    "print(\"Tests output to\", chinese_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cf9c108-cc10-47e0-8f63-1afb27c75eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 768 (451 1s and 317 0s) | TEST: 193 (113 1s and 80 0s)\n",
      "TRAIN: 769 (451 1s and 318 0s) | TEST: 192 (113 1s and 79 0s)\n",
      "TRAIN: 769 (451 1s and 318 0s) | TEST: 192 (113 1s and 79 0s)\n",
      "TRAIN: 769 (451 1s and 318 0s) | TEST: 192 (113 1s and 79 0s)\n",
      "TRAIN: 769 (452 1s and 317 0s) | TEST: 192 (112 1s and 80 0s)\n",
      "Tests output to Multilingual_Data/spanish-5_fold_v0\n"
     ]
    }
   ],
   "source": [
    "spanish_corpus = pd.read_csv(spanish_src, index_col=0)\n",
    "spanish_corpus = spanish_corpus[['Texto editado', 'Es Eufemistico']]\n",
    "spanish_corpus = spanish_corpus.rename(columns={'Texto editado':'text', 'Es Eufemistico':'label'})\n",
    "spanish_corpus = spanish_corpus.sample(frac=1)\n",
    "\n",
    "k_folds = get_k_fold_splits(spanish_corpus, k=5)\n",
    "for i in range(0, len(k_folds)): # for each fold, save the first element as the train df and the second as the test df\n",
    "    k_folds[i][0].to_csv(spanish_dest + '/hf_train_' + str(i) + '.csv', index=False)\n",
    "    k_folds[i][1].to_csv(spanish_dest + '/hf_test_' + str(i) + '.csv', index=False)\n",
    "print(\"Tests output to\", spanish_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f533691d-e193-4bb3-9387-fc57ef166062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 1553 (1024 1s and 529 0s) | TEST: 389 (257 1s and 132 0s)\n",
      "TRAIN: 1553 (1025 1s and 528 0s) | TEST: 389 (256 1s and 133 0s)\n",
      "TRAIN: 1554 (1025 1s and 529 0s) | TEST: 388 (256 1s and 132 0s)\n",
      "TRAIN: 1554 (1025 1s and 529 0s) | TEST: 388 (256 1s and 132 0s)\n",
      "TRAIN: 1554 (1025 1s and 529 0s) | TEST: 388 (256 1s and 132 0s)\n",
      "Tests output to Multilingual_Data/yoruba-5_fold_v1.1\n"
     ]
    }
   ],
   "source": [
    "yoruba_corpus = pd.read_csv(yoruba_src, index_col=0)\n",
    "yoruba_corpus = yoruba_corpus[['text', 'Rating']]\n",
    "yoruba_corpus = yoruba_corpus.rename(columns={'text':'text', 'Rating':'label'})\n",
    "yoruba_corpus = yoruba_corpus.sample(frac=1)\n",
    "\n",
    "k_folds = get_k_fold_splits(yoruba_corpus, k=5)\n",
    "for i in range(0, len(k_folds)): # for each fold, save the first element as the train df and the second as the test df\n",
    "    k_folds[i][0].to_csv(yoruba_dest + '/hf_train_' + str(i) + '.csv', index=False)\n",
    "    k_folds[i][1].to_csv(yoruba_dest + '/hf_test_' + str(i) + '.csv', index=False)\n",
    "print(\"Tests output to\", yoruba_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51e88b0d-f520-465b-b294-a85bc98d10ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 1561 (1106 1s and 455 0s) | TEST: 391 (277 1s and 114 0s)\n",
      "TRAIN: 1561 (1106 1s and 455 0s) | TEST: 391 (277 1s and 114 0s)\n",
      "TRAIN: 1562 (1106 1s and 456 0s) | TEST: 390 (277 1s and 113 0s)\n",
      "TRAIN: 1562 (1107 1s and 455 0s) | TEST: 390 (276 1s and 114 0s)\n",
      "TRAIN: 1562 (1107 1s and 455 0s) | TEST: 390 (276 1s and 114 0s)\n",
      "Tests output to Multilingual_Data/english-5-fold_v0\n"
     ]
    }
   ],
   "source": [
    "english_corpus = pd.read_csv(english_src, index_col=0)\n",
    "english_corpus = english_corpus[['edited_text', 'is_euph']]\n",
    "english_corpus = english_corpus.rename(columns={'edited_text':'text', 'is_euph':'label'})\n",
    "english_corpus = english_corpus.sample(frac=1)\n",
    "\n",
    "k_folds = get_k_fold_splits(english_corpus, k=5)\n",
    "for i in range(0, len(k_folds)): # for each fold, save the first element as the train df and the second as the test df\n",
    "    k_folds[i][0].to_csv(english_dest + '/hf_train_' + str(i) + '.csv', index=False)\n",
    "    k_folds[i][1].to_csv(english_dest + '/hf_test_' + str(i) + '.csv', index=False)\n",
    "print(\"Tests output to\", english_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d6ac5c-722b-4629-b0af-0bdf45e139e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add <> and re-run classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c136e651-d63d-43ab-aac0-aa6fedaafa60",
   "metadata": {},
   "source": [
    "## Process Metrics\n",
    "Written to extract best-run metrics from `results.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a060e3bc-7dd3-4b61-b621-a416421c4362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.928018</td>\n",
       "      <td>0.950893</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>72.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.953786</td>\n",
       "      <td>0.968468</td>\n",
       "      <td>0.981735</td>\n",
       "      <td>76.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.909526</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.968037</td>\n",
       "      <td>68.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.914186</td>\n",
       "      <td>0.942222</td>\n",
       "      <td>0.968037</td>\n",
       "      <td>69.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.956738</td>\n",
       "      <td>0.960352</td>\n",
       "      <td>0.995434</td>\n",
       "      <td>73.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVG</th>\n",
       "      <td>0.932451</td>\n",
       "      <td>0.951998</td>\n",
       "      <td>0.977169</td>\n",
       "      <td>71.6</td>\n",
       "      <td>10.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           F1         P         R    tn    fp   fn     tp\n",
       "0    0.928018  0.950893  0.972603  72.0  11.0  6.0  213.0\n",
       "1    0.953786  0.968468  0.981735  76.0   7.0  4.0  215.0\n",
       "2    0.909526  0.938053  0.968037  68.0  14.0  7.0  212.0\n",
       "3    0.914186  0.942222  0.968037  69.0  13.0  7.0  212.0\n",
       "4    0.956738  0.960352  0.995434  73.0   9.0  1.0  218.0\n",
       "AVG  0.932451  0.951998  0.977169  71.6  10.8  5.0  214.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "FOLDER = 'Multilingual_Data/chinese-5_fold_v0.1'\n",
    "df = pd.read_csv(FOLDER + '/results_xlm_large.csv', index_col=0)\n",
    "results = pd.DataFrame(columns=['F1', 'P', 'R', 'tn', 'fp', 'fn', 'tp'])\n",
    "k = 5 # number of tests\n",
    "num_epochs = 10\n",
    "\n",
    "# for each test, select the row with the best F1, then evaluate separate F1s for pos vs neg examples\n",
    "for x in range(0, k):\n",
    "    test = df.loc[num_epochs*x:num_epochs*x+9] # select rows from this test (first epoch:last epoch)\n",
    "    max_f1 = test.loc[test['f1'].idxmax()] # using F1, select the best row (epoch) from this test\n",
    "    stats = max_f1[0:7].tolist() # take the base stats from the best row\n",
    "    results.loc[len(results.index)] = stats\n",
    "results.loc['AVG'] = results.mean() # compute an average row\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1287f1f1-9506-4c8d-a50e-362b4bc817a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental\n",
    "import re\n",
    "def hfify(df):\n",
    "    # df = df.drop(['keyword', 'category', 'type', 'euph_status', 'sentence', PROPERTY], axis=1)\n",
    "    df['preprocessed_text'] = \"\"\n",
    "    for i, row in df.iterrows():\n",
    "        text = df.loc[i, 'text']\n",
    "        text = re.sub(r\"[<>]\", \" \", text) # we're removing brackets...\n",
    "        df.loc[i, 'preprocessed_text'] = \" \".join(text.split()) \n",
    "    df = df[['preprocessed_text','label']]\n",
    "    df = df.rename(columns={'preprocessed_text':'text'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91a515a2-31b5-4a54-91ed-cb76ee82410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "FOLDER = 'Multilingual_Data/chinese-5_fold_v0/'\n",
    "DEST_FOLDER = 'Multilingual_Data/chinese-5_fold_v0.1/'\n",
    "for n in range(0, 5):\n",
    "    df = pd.read_csv(FOLDER + 'hf_train_' + str(n) + '.csv')\n",
    "    df = hfify(df)\n",
    "    df.to_csv(DEST_FOLDER + 'hf_train_' + str(n) + '.csv')\n",
    "    df = pd.read_csv(FOLDER + 'hf_test_' + str(n) + '.csv')\n",
    "    df = hfify(df)\n",
    "    df.to_csv(DEST_FOLDER + 'hf_test_' + str(n) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b624d6a-34b2-477b-934e-4f9eadf7418b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'毛坯房 厨房贴砖 做防水  卫生间 贴砖 文化砖 刷腻子 家里所有的家具都是请木工制作的'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"毛坯房 厨房贴砖 做防水 <卫生间>贴砖 文化砖 刷腻子 家里所有的家具都是请木工制作的\"\n",
    "t = re.sub(r\"<>\", \" \", t) # we're removing brackets...\n",
    "t = re.sub(r\"[<>]\", \" \", t)\n",
    "t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
