{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29279f68-9e20-4bd3-a79f-751066dfb99c",
   "metadata": {},
   "source": [
    "# Error analysis of models in the vagueness experiments.\n",
    "The notebook is meant for analyzing errors - systematically looking at PETs which were misclassified, identifying rows for qualitative analysis, etc.\n",
    "\n",
    "Notes:\n",
    "What are we seeing? Some of the examples it's getting wrong so far seem to be ones that are truly uncertain (even to me, human) - not clear what the label should be. But some are just plain wrong.\n",
    "For the PETs analysis, I think I should include a VAGUE label, as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "813c43c1-1f18-46af-8a86-0a6a20db3493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = 'Vagueness_Splits/Test_5/PET_balanced_mixed_mixed/'\n",
    "results = pd.read_csv(path + 'PET_balanced_mixed_mixed_results_unscrambled.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a9b484-ef04-4f78-bafa-ab55d1d7f075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PET</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Total</th>\n",
       "      <th>pct</th>\n",
       "      <th>status</th>\n",
       "      <th>vague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>disabled_1</td>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>0.066</td>\n",
       "      <td>sometimes_euph</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>late_0</td>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>0.152</td>\n",
       "      <td>sometimes_euph</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>income inequality_1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>always_euph</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aging_0</td>\n",
       "      <td>26</td>\n",
       "      <td>45</td>\n",
       "      <td>0.578</td>\n",
       "      <td>sometimes_euph</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>inner city_1</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>always_euph</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>latrine_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>always_euph</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>seasoned_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sometimes_euph</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>invalid_0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sometimes_euph</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>negative cash flow_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>always_euph</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>physically challenged_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>always_euph</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         PET Incorrect Total    pct          status vague\n",
       "52                disabled_1         4    61  0.066  sometimes_euph     1\n",
       "58                    late_0         7    46  0.152  sometimes_euph     0\n",
       "48       income inequality_1         0    45    0.0     always_euph     1\n",
       "5                    aging_0        26    45  0.578  sometimes_euph     0\n",
       "12              inner city_1         0    43    0.0     always_euph     1\n",
       "..                       ...       ...   ...    ...             ...   ...\n",
       "23                 latrine_1         1     1    1.0     always_euph     0\n",
       "149               seasoned_0         0     1    0.0  sometimes_euph     0\n",
       "135                invalid_0         1     1    1.0  sometimes_euph     0\n",
       "64      negative cash flow_1         0     1    0.0     always_euph     1\n",
       "180  physically challenged_1         0     1    0.0     always_euph     1\n",
       "\n",
       "[181 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# keep track of cumulative PET errors from all tests\n",
    "error_dict = {}\n",
    "\n",
    "for x in range(0, 10):\n",
    "    # find the best preds\n",
    "    test = results.loc[10*x:10*x+9]\n",
    "    max_f1 = test.loc[test['f1'].idxmax()] # this is the best row from this test\n",
    "    \n",
    "    best_preds = max_f1['preds'].replace(' ', ', ') # the labels don't have a comma between them...\n",
    "    best_preds = ast.literal_eval(best_preds)\n",
    "    \n",
    "    # attach them to the examples\n",
    "    ref_df = pd.read_csv(path + '/test_' + str(x) + '.csv')\n",
    "    ref_df['preds'] = best_preds\n",
    "    # display(ref_df)\n",
    "    # save for qualitative analysis - essentially, just the test file with preds from the best epoch\n",
    "    ref_df.to_csv('Vagueness_Error_Analysis/test_' + str(x) + '.csv')\n",
    "    \n",
    "    # now go through and update the error dict for this test\n",
    "    for i, row in ref_df.iterrows():\n",
    "        label = ref_df.loc[i]['is_euph']\n",
    "        pred = ref_df.loc[i]['preds']\n",
    "        PET = ref_df.loc[i]['type'] + \"_\" + str(label)\n",
    "        vague_label = ref_df.loc[i]['is_vague']\n",
    "        status = ref_df.loc[i]['euph_status']\n",
    "\n",
    "        if PET not in error_dict:\n",
    "            error_dict[PET] = [0, 1, status, vague_label]\n",
    "        else:\n",
    "            error_dict[PET][1] += 1\n",
    "\n",
    "        if (label != pred):\n",
    "            error_dict[PET][0] += 1\n",
    "\n",
    "# put the results into a df\n",
    "error_df = pd.DataFrame(columns = ['PET', 'Incorrect', 'Total', 'pct'])\n",
    "\n",
    "for PET, e in error_dict.items():\n",
    "    new_row = pd.Series({'PET': PET,\n",
    "                         'status':e[2],\n",
    "                         'vague':e[3],\n",
    "                    'Incorrect': e[0],\n",
    "                    'Total': e[1],\n",
    "                    'pct': round(e[0]/e[1], 3)\n",
    "                   })\n",
    "    error_df = pd.concat([error_df, new_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "error_df = error_df.sort_values(by=['Total'], ascending=False)\n",
    "    \n",
    "display(error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aea816b-6551-4454-ad88-d65b2dbd8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df.sto_csv('VET_Test_5_Errors_by_PET_2.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df483751-e171-4bac-b958-91e6ebb6f9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>140</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>140</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.522433</td>\n",
       "      <td>0.721925</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>135</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.648601</td>\n",
       "      <td>0.771605</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>125</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.703192</td>\n",
       "      <td>0.793939</td>\n",
       "      <td>0.935714</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>131</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.766996</td>\n",
       "      <td>0.823171</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>135</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.789446</td>\n",
       "      <td>0.841772</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>133</td>\n",
       "      <td>[1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.744607</td>\n",
       "      <td>0.812121</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>134</td>\n",
       "      <td>[1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.740815</td>\n",
       "      <td>0.808383</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>135</td>\n",
       "      <td>[1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.781450</td>\n",
       "      <td>0.836478</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>133</td>\n",
       "      <td>[1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          f1  precision    recall  tn  fp  fn   tp  \\\n",
       "0   0.411765   0.700000  1.000000   0   0  60  140   \n",
       "1   0.411765   0.700000  1.000000   0   0  60  140   \n",
       "2   0.522433   0.721925  0.964286   8   5  52  135   \n",
       "3   0.648601   0.771605  0.892857  23  15  37  125   \n",
       "4   0.703192   0.793939  0.935714  26   9  34  131   \n",
       "..       ...        ...       ...  ..  ..  ..  ...   \n",
       "95  0.766996   0.823171  0.964286  31   5  29  135   \n",
       "96  0.789446   0.841772  0.950000  35   7  25  133   \n",
       "97  0.744607   0.812121  0.957143  29   6  31  134   \n",
       "98  0.740815   0.808383  0.964286  28   5  32  135   \n",
       "99  0.781450   0.836478  0.950000  34   7  26  133   \n",
       "\n",
       "                                                preds  \n",
       "0   [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...  \n",
       "1   [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...  \n",
       "2   [1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0...  \n",
       "3   [1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0...  \n",
       "4   [1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0...  \n",
       "..                                                ...  \n",
       "95  [1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1...  \n",
       "96  [1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1...  \n",
       "97  [1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1...  \n",
       "98  [1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1...  \n",
       "99  [1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1...  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ed00cc-ed75-439c-844c-54040fd6c2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>keyword</th>\n",
       "      <th>edited_text</th>\n",
       "      <th>is_euph</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "      <th>euph_status</th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_vague</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1039</td>\n",
       "      <td>disabled</td>\n",
       "      <td>I was homeschooled up until 5th grade, which i...</td>\n",
       "      <td>1</td>\n",
       "      <td>physical/mental attributes</td>\n",
       "      <td>disabled</td>\n",
       "      <td>sometimes_euph</td>\n",
       "      <td>I couldn't help but feel like I was in a schoo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1032</td>\n",
       "      <td>disabled</td>\n",
       "      <td>I am a &lt;disabled&gt; Vietnam veteran who served h...</td>\n",
       "      <td>1</td>\n",
       "      <td>physical/mental attributes</td>\n",
       "      <td>disabled</td>\n",
       "      <td>sometimes_euph</td>\n",
       "      <td>I am a disabled Vietnam veteran who served hon...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>311</td>\n",
       "      <td>inner city</td>\n",
       "      <td>Faulty logic, irrelevant and/or non-existent r...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "      <td>inner city</td>\n",
       "      <td>always_euph</td>\n",
       "      <td>Having spent the better part of 26 years worki...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>308</td>\n",
       "      <td>inner city</td>\n",
       "      <td>SMMNRA hires diverse high school students from...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "      <td>inner city</td>\n",
       "      <td>always_euph</td>\n",
       "      <td>Conservation Corps provides jobs for inner cit...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>578</td>\n",
       "      <td>people of color</td>\n",
       "      <td>HEATHER MCGHEE: It's actually these brown and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>physical/mental attributes</td>\n",
       "      <td>people/persons of color</td>\n",
       "      <td>always_euph</td>\n",
       "      <td>HEATHER MCGHEE It's actually these brown and b...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>87</td>\n",
       "      <td>freedom fighters</td>\n",
       "      <td>The fast and furious mentality of arming Ameri...</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "      <td>freedom fighter</td>\n",
       "      <td>always_euph</td>\n",
       "      <td>Obama would probably love to fully support the...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1335</td>\n",
       "      <td>troubled</td>\n",
       "      <td>My parents' four and a half decades were not e...</td>\n",
       "      <td>1</td>\n",
       "      <td>physical/mental attributes</td>\n",
       "      <td>troubled</td>\n",
       "      <td>sometimes_euph</td>\n",
       "      <td>Both were refugees from troubled childhoods an...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1784</td>\n",
       "      <td>intoxicated</td>\n",
       "      <td>A form was downloaded from the Internet and fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>substances</td>\n",
       "      <td>intoxicated</td>\n",
       "      <td>sometimes_euph</td>\n",
       "      <td>We were intoxicated in the early stage of this...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>723</td>\n",
       "      <td>droppings</td>\n",
       "      <td>bupkes Not a word for polite company. Bubkes o...</td>\n",
       "      <td>1</td>\n",
       "      <td>bodily functions</td>\n",
       "      <td>droppings</td>\n",
       "      <td>always_euph</td>\n",
       "      <td>Bubkes or bobkes may be related to the Polish ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1291</td>\n",
       "      <td>late</td>\n",
       "      <td>\"History has not been kind to Cassandra or Chi...</td>\n",
       "      <td>1</td>\n",
       "      <td>death</td>\n",
       "      <td>late</td>\n",
       "      <td>sometimes_euph</td>\n",
       "      <td>Those who warn of disasters have been accused ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0           keyword  \\\n",
       "0          1039          disabled   \n",
       "1          1032          disabled   \n",
       "2           311        inner city   \n",
       "3           308        inner city   \n",
       "4           578   people of color   \n",
       "..          ...               ...   \n",
       "195          87  freedom fighters   \n",
       "196        1335          troubled   \n",
       "197        1784       intoxicated   \n",
       "198         723         droppings   \n",
       "199        1291              late   \n",
       "\n",
       "                                           edited_text  is_euph  \\\n",
       "0    I was homeschooled up until 5th grade, which i...        1   \n",
       "1    I am a <disabled> Vietnam veteran who served h...        1   \n",
       "2    Faulty logic, irrelevant and/or non-existent r...        1   \n",
       "3    SMMNRA hires diverse high school students from...        1   \n",
       "4    HEATHER MCGHEE: It's actually these brown and ...        1   \n",
       "..                                                 ...      ...   \n",
       "195  The fast and furious mentality of arming Ameri...        1   \n",
       "196  My parents' four and a half decades were not e...        1   \n",
       "197  A form was downloaded from the Internet and fa...        0   \n",
       "198  bupkes Not a word for polite company. Bubkes o...        1   \n",
       "199  \"History has not been kind to Cassandra or Chi...        1   \n",
       "\n",
       "                       category                     type     euph_status  \\\n",
       "0    physical/mental attributes                 disabled  sometimes_euph   \n",
       "1    physical/mental attributes                 disabled  sometimes_euph   \n",
       "2                      politics               inner city     always_euph   \n",
       "3                      politics               inner city     always_euph   \n",
       "4    physical/mental attributes  people/persons of color     always_euph   \n",
       "..                          ...                      ...             ...   \n",
       "195                    politics          freedom fighter     always_euph   \n",
       "196  physical/mental attributes                 troubled  sometimes_euph   \n",
       "197                  substances              intoxicated  sometimes_euph   \n",
       "198            bodily functions                droppings     always_euph   \n",
       "199                       death                     late  sometimes_euph   \n",
       "\n",
       "                                              sentence  is_vague  preds  \n",
       "0    I couldn't help but feel like I was in a schoo...         1      1  \n",
       "1    I am a disabled Vietnam veteran who served hon...         1      1  \n",
       "2    Having spent the better part of 26 years worki...         1      1  \n",
       "3    Conservation Corps provides jobs for inner cit...         1      1  \n",
       "4    HEATHER MCGHEE It's actually these brown and b...         0      1  \n",
       "..                                                 ...       ...    ...  \n",
       "195  Obama would probably love to fully support the...         1      1  \n",
       "196  Both were refugees from troubled childhoods an...         1      1  \n",
       "197  We were intoxicated in the early stage of this...         1      1  \n",
       "198  Bubkes or bobkes may be related to the Polish ...         0      1  \n",
       "199  Those who warn of disasters have been accused ...         0      1  \n",
       "\n",
       "[200 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# populate a certain DF with the preds for error analysis\n",
    "import ast\n",
    "\n",
    "x = 1 # the number of the test \n",
    "\n",
    "# find the best preds\n",
    "test = results.loc[10*x:10*x+9]\n",
    "max_f1 = test.loc[test['f1'].idxmax()] # this is the best row from this test\n",
    "\n",
    "best_preds = max_f1['preds'].replace(' ', ', ') # the labels don't have a comma between them...\n",
    "best_preds = ast.literal_eval(best_preds)\n",
    "\n",
    "# attach them to the examples\n",
    "ref_df = pd.read_csv(path + '/test_' + str(x) + '.csv')\n",
    "ref_df['preds'] = best_preds\n",
    "\n",
    "ref_df\n",
    "ref_df.to_csv(\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c14e57e-a081-48a2-8e41-4c92f435bb7d",
   "metadata": {},
   "source": [
    "# Topic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e8caf50-12ea-4b50-86d3-d44198d54fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stopwords(text):\n",
    "    stopwords = []\n",
    "    with open(text,'rb') as f:\n",
    "        content = f.read()\n",
    "        content = content.split(b'\\r\\n')\n",
    "        for line in content:\n",
    "            stopwords.append(line.decode('utf-8'))\n",
    "    return stopwords\n",
    "\n",
    "def sum_similarity(model, phrase, topic_list):\n",
    "    score = 0\n",
    "    for topic in topic_list:\n",
    "        try:\n",
    "            similarity = model.wv.similarity(phrase, topic)\n",
    "            # \"reward\" the phrases with a high similarity to a particular category, but maybe not others\n",
    "            if (similarity > 0.50):\n",
    "                # return 1\n",
    "                score += 1\n",
    "            # if (similarity > 0):\n",
    "            #     score += similarity\n",
    "        except: # if no matches to phrase in w2v model\n",
    "            score += 0\n",
    "    return score\n",
    "\n",
    "def preprocess(s):\n",
    "    s = s.strip()\n",
    "    s = re.sub(r'(##\\d*\\W)|<\\w>|,|;|:|--|\\(|\\)|#|%|\\\\|\\/|\\.|\\*|\\+|@|>|<|\\?|!', '', s)\n",
    "    s = re.sub(r'\\s\\s+', ' ', s)\n",
    "    s = s.lower()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c51736d-ef5e-49c0-945d-7d22b71681d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "\n",
    "w2v_path = '../PETDetection/data/wv_model_7'\n",
    "stopwords_path = '../PETDetection/data/stopwords.txt'\n",
    "\n",
    "model = Word2Vec.load(w2v_path)\n",
    "stopwords = read_stopwords(stopwords_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad0ec882-d995-4573-85b0-ca6964d3ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "full_df = pd.read_csv(\"VET_Corpus_0.2.csv\", index_col=0)\n",
    "df = pd.read_csv(\"Vagueness_Errors_4.0.2_base.csv\", index_col=0)\n",
    "\n",
    "full_df['topic_sim_sum'] = -1\n",
    "full_df['topic_sim_index'] = -1\n",
    "\n",
    "topic_list = ['politics', 'death', 'kill', 'crime',\n",
    "       'drugs', 'alcohol', 'fat', 'old', 'poor', 'cheap',\n",
    "       'sex', 'sexual',\n",
    "       'employment', 'job', 'disability',\n",
    "       'pregnant', 'bathroom', 'sickness', \n",
    "        'race', 'racial', 'religion', 'government'\n",
    "      ]\n",
    "\n",
    "# topic_list = ['die', 'kill']\n",
    "\n",
    "for i, row in full_df.iterrows():\n",
    "    text = full_df.loc[i, 'edited_text']\n",
    "    text = preprocess(text)\n",
    "    # print(text)\n",
    "    words = text.split()\n",
    "    # print(words)\n",
    "    total_sim = 0 # total amount of topic similarity\n",
    "    for word in words:\n",
    "        if (word in stopwords):\n",
    "            continue\n",
    "        sim = sum_similarity(model, word, topic_list)\n",
    "        if (sim == -1):\n",
    "            total_sim += 10\n",
    "        else:\n",
    "            total_sim += sim\n",
    "        #print(word, sim)\n",
    "    full_df.loc[i, 'topic_sim_sum'] = total_sim\n",
    "    full_df.loc[i, 'topic_sim_index'] = total_sim/len(words)\n",
    "    \n",
    "df['topic_sim_sum'] = -1\n",
    "df['topic_sim_index'] = -1\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    text = df.loc[i, 'edited_text']\n",
    "    text = preprocess(text)\n",
    "    # print(text)\n",
    "    words = text.split()\n",
    "    # print(words)\n",
    "    total_sim = 0 # total amount of topic similarity\n",
    "    for word in words:\n",
    "        if (word in stopwords):\n",
    "            continue\n",
    "        sim = sum_similarity(model, word, topic_list)\n",
    "        if (sim == -1):\n",
    "            total_sim += 10\n",
    "        else:\n",
    "            total_sim += sim\n",
    "        #print(word, sim)\n",
    "    df.loc[i, 'topic_sim_sum'] = total_sim\n",
    "    df.loc[i, 'topic_sim_index'] = total_sim/len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52eab5eb-58d9-432f-a662-4bbfc8428776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUPH_FULL_DATASET: 1383 7.900939985538684 0.1288409387266836\n",
      "NON-EUPH_FULL_DATASET: 569 5.5834797891036905 0.09190001233924402\n",
      "VAGUE_FULL_DATASET: 769 6.843953185955787 0.1092213093148404\n",
      "NON-VAGUE_FULL_DATASET: 1183 7.4733727810650885 0.12382665969308648\n",
      "EUPH_VAGUE_FULL_DATASET: 408 7.948529411764706 0.12585831108466147\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 361 5.595567867036011 0.0904182713035185\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 975 7.881025641025641 0.13008905367842208\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 208 5.5625 0.0944716878868255\n",
      "\n",
      "EUPH_ERROR_DATASET: 63 4.095238095238095 0.06948433691319826\n",
      "NON-EUPH_ERROR_DATASET: 80 7.6 0.12123938467358246\n",
      "VAGUE_ERROR_DATASET: 66 5.96969696969697 0.09578367216544666\n",
      "NON-VAGUE_ERROR_DATASET: 77 6.12987012987013 0.10071352774673513\n",
      "EUPH_VAGUE_ERROR_DATASET: 21 3.5714285714285716 0.05597689022746226\n",
      "NON-EUPH_VAGUE_ERROR_DATASET: 45 7.088888888888889 0.11436017040317273\n",
      "EUPH_NON-VAGUE_ERROR_DATASET: 42 4.357142857142857 0.07623806025606626\n",
      "NON-EUPH_NON-VAGUE_ERROR_DATASET: 35 8.257142857142858 0.13008408873553784\n"
     ]
    }
   ],
   "source": [
    "euph_examples = full_df.loc[full_df['is_euph'] == 1]\n",
    "noneuph_examples = full_df.loc[full_df['is_euph'] == 0]\n",
    "vague_examples = full_df.loc[full_df['is_vague'] == 1]\n",
    "nonvague_examples = full_df.loc[full_df['is_vague'] == 0]\n",
    "euph_vague_examples = euph_examples.loc[euph_examples['is_vague']==1]\n",
    "noneuph_vague_examples = noneuph_examples.loc[noneuph_examples['is_vague']==1]\n",
    "euph_nonvague_examples = euph_examples.loc[euph_examples['is_vague']==0]\n",
    "noneuph_nonvague_examples = noneuph_examples.loc[noneuph_examples['is_vague']==0]\n",
    "\n",
    "print(\"EUPH_FULL_DATASET:\", len(euph_examples), euph_examples.loc[:, 'topic_sim_sum'].mean(), euph_examples.loc[:, 'topic_sim_index'].mean())\n",
    "print(\"NON-EUPH_FULL_DATASET:\", len(noneuph_examples), noneuph_examples.loc[:, 'topic_sim_sum'].mean(), noneuph_examples.loc[:, 'topic_sim_index'].mean())\n",
    "print(\"VAGUE_FULL_DATASET:\", len(vague_examples), vague_examples.loc[:, 'topic_sim_sum'].mean(), vague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "print(\"NON-VAGUE_FULL_DATASET:\", len(nonvague_examples), nonvague_examples.loc[:, 'topic_sim_sum'].mean(), nonvague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "print(\"EUPH_VAGUE_FULL_DATASET:\", len(euph_vague_examples), euph_vague_examples.loc[:, 'topic_sim_sum'].mean(), euph_vague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "print(\"NON-EUPH_VAGUE_FULL_DATASET:\", len(noneuph_vague_examples), noneuph_vague_examples.loc[:, 'topic_sim_sum'].mean(), noneuph_vague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "print(\"EUPH_NON-VAGUE_FULL_DATASET:\", len(euph_nonvague_examples), euph_nonvague_examples.loc[:, 'topic_sim_sum'].mean(), euph_nonvague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "print(\"NON-EUPH_NON-VAGUE_FULL_DATASET:\", len(noneuph_nonvague_examples), noneuph_nonvague_examples.loc[:, 'topic_sim_sum'].mean(), noneuph_nonvague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "print()\n",
    "\n",
    "cropped_df = df.loc[df['freq'] >= 10]\n",
    "err_euph_examples = cropped_df.loc[cropped_df['is_euph'] == 1]\n",
    "err_noneuph_examples = cropped_df.loc[cropped_df['is_euph'] == 0]\n",
    "err_vague_examples = cropped_df.loc[cropped_df['is_vague'] == 1]\n",
    "err_nonvague_examples = cropped_df.loc[cropped_df['is_vague'] == 0]\n",
    "err_euph_vague_examples = err_euph_examples.loc[err_euph_examples['is_vague']==1]\n",
    "err_noneuph_vague_examples = err_noneuph_examples.loc[err_noneuph_examples['is_vague']==1]\n",
    "err_euph_nonvague_examples = err_euph_examples.loc[err_euph_examples['is_vague']==0]\n",
    "err_noneuph_nonvague_examples = err_noneuph_examples.loc[err_noneuph_examples['is_vague']==0]\n",
    "\n",
    "print(\"EUPH_ERROR_DATASET:\", len(err_euph_examples), err_euph_examples.loc[:, 'topic_sim_sum'].mean(), err_euph_examples.loc[:, 'topic_sim_index'].mean())\n",
    "print(\"NON-EUPH_ERROR_DATASET:\", len(err_noneuph_examples), err_noneuph_examples.loc[:, 'topic_sim_sum'].mean(), err_noneuph_examples.loc[:, 'topic_sim_index'].mean())\n",
    "print(\"VAGUE_ERROR_DATASET:\", len(err_vague_examples), err_vague_examples.loc[:, 'topic_sim_sum'].mean(), err_vague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "print(\"NON-VAGUE_ERROR_DATASET:\", len(err_nonvague_examples), err_nonvague_examples.loc[:, 'topic_sim_sum'].mean(), err_nonvague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "print(\"EUPH_VAGUE_ERROR_DATASET:\", len(err_euph_vague_examples), err_euph_vague_examples.loc[:, 'topic_sim_sum'].mean(), err_euph_vague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "print(\"NON-EUPH_VAGUE_ERROR_DATASET:\", len(err_noneuph_vague_examples), err_noneuph_vague_examples.loc[:, 'topic_sim_sum'].mean(), err_noneuph_vague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "print(\"EUPH_NON-VAGUE_ERROR_DATASET:\", len(err_euph_nonvague_examples), err_euph_nonvague_examples.loc[:, 'topic_sim_sum'].mean(), err_euph_nonvague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "print(\"NON-EUPH_NON-VAGUE_ERROR_DATASET:\", len(err_noneuph_nonvague_examples), err_noneuph_nonvague_examples.loc[:, 'topic_sim_sum'].mean(), err_noneuph_nonvague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "# euph_vague_examples = euph_examples.loc[euph_examples['is_vague'] == 1]\n",
    "# euph_unvague_examples = euph_examples.loc[euph_examples['is_vague'] == 0]\n",
    "# print(euph_vague_examples.loc[:, 'topic_sim_sum'].mean())\n",
    "# print(euph_vague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "# print(euph_unvague_examples.loc[:, 'topic_sim_sum'].mean())\n",
    "# print(euph_unvague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "# print()\n",
    "\n",
    "# noneuph_vague_examples = noneuph_examples.loc[noneuph_examples['is_vague'] == 1]\n",
    "# noneuph_unvague_examples = noneuph_examples.loc[noneuph_examples['is_vague'] == 0]\n",
    "# print(noneuph_vague_examples.loc[:, 'topic_sim_sum'].mean())\n",
    "# print(noneuph_vague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "# print(noneuph_unvague_examples.loc[:, 'topic_sim_sum'].mean())\n",
    "# print(noneuph_unvague_examples.loc[:, 'topic_sim_index'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe0d7248-7991-4954-aea8-4e240023e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv('Dataset_Topic_Analysis_2.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2050df50-bc25-4246-a6c3-5aa8b4e6fa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# x = np.random.normal(170, 10, 250)\n",
    "a = np.array(euph_vague_examples.loc[:, 'topic_sim_sum'])\n",
    "b = np.array(noneuph_vague_examples.loc[:, 'topic_sim_sum'])\n",
    "c = np.array(euph_nonvague_examples.loc[:, 'topic_sim_sum'])\n",
    "d = np.array(noneuph_nonvague_examples.loc[:, 'topic_sim_sum'])\n",
    "\n",
    "# histograms\n",
    "bins = np.linspace(0, 40, 8)\n",
    "plt.hist(a, bins, alpha=0.5, label='euph_vague')\n",
    "plt.hist(b, bins, alpha=0.5, label='noneuph_vague')\n",
    "plt.hist(c, bins, alpha=0.5, label='euph_nonvague')\n",
    "plt.hist(d, bins, alpha=0.5, label='noneuph_nonvague')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# box plot\n",
    "data = [a, b, c, d]\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "# Creating axes instance\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "# Creating plot\n",
    "\n",
    "bp = ax.boxplot(data)\n",
    "plt.xticks([1, 2, 3, 4], ['euph_vague', 'noneuph_vague', 'euph_nonvague', 'noneuph_nonvague'])\n",
    "# show plot\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6814c0-c6f2-4c2f-8717-8d5dd0ed63c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching through individual training files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d646189b-9f33-4668-9df9-e82bdb4b01f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_0.csv\n",
      "EUPH_FULL_DATASET: 84 7.75 0.11994893125596198\n",
      "NON-EUPH_FULL_DATASET: 84 6.440476190476191 0.10346531896550912\n",
      "VAGUE_FULL_DATASET: 84 7.404761904761905 0.11248878406873682\n",
      "NON-VAGUE_FULL_DATASET: 84 6.785714285714286 0.11092546615273428\n",
      "EUPH_VAGUE_FULL_DATASET: 42 7.166666666666667 0.10720494210815897\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 42 7.642857142857143 0.11777262602931471\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 42 8.333333333333334 0.13269292040376507\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 42 5.238095238095238 0.08915801190170354\n",
      "\n",
      "test_1.csv\n",
      "EUPH_FULL_DATASET: 84 7.869047619047619 0.1181047643340213\n",
      "NON-EUPH_FULL_DATASET: 84 5.285714285714286 0.08698771470130652\n",
      "VAGUE_FULL_DATASET: 84 6.428571428571429 0.09597524053475581\n",
      "NON-VAGUE_FULL_DATASET: 84 6.726190476190476 0.10911723850057202\n",
      "EUPH_VAGUE_FULL_DATASET: 42 8.714285714285714 0.1248166327554668\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 42 4.142857142857143 0.06713384831404479\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 42 7.023809523809524 0.1113928959125759\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 42 6.428571428571429 0.10684158108856823\n",
      "\n",
      "test_2.csv\n",
      "EUPH_FULL_DATASET: 84 7.595238095238095 0.12717900470078553\n",
      "NON-EUPH_FULL_DATASET: 84 5.214285714285714 0.08827201414233092\n",
      "VAGUE_FULL_DATASET: 84 6.583333333333333 0.10736031100997023\n",
      "NON-VAGUE_FULL_DATASET: 84 6.226190476190476 0.10809070783314623\n",
      "EUPH_VAGUE_FULL_DATASET: 42 7.785714285714286 0.12747440081521128\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 42 5.380952380952381 0.08724622120472911\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 42 7.404761904761905 0.12688360858635975\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 42 5.0476190476190474 0.08929780707993273\n",
      "\n",
      "test_3.csv\n",
      "EUPH_FULL_DATASET: 84 7.285714285714286 0.12942995873858903\n",
      "NON-EUPH_FULL_DATASET: 84 5.392857142857143 0.08972730310651374\n",
      "VAGUE_FULL_DATASET: 84 6.535714285714286 0.10170620290341313\n",
      "NON-VAGUE_FULL_DATASET: 84 6.142857142857143 0.11745105894168961\n",
      "EUPH_VAGUE_FULL_DATASET: 42 6.904761904761905 0.10708784623759969\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 42 6.166666666666667 0.09632455956922654\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 42 7.666666666666667 0.15177207123957842\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 42 4.619047619047619 0.08313004664380089\n",
      "\n",
      "test_4.csv\n",
      "EUPH_FULL_DATASET: 84 7.273809523809524 0.11976654988299229\n",
      "NON-EUPH_FULL_DATASET: 84 5.7976190476190474 0.09517179788714596\n",
      "VAGUE_FULL_DATASET: 84 6.392857142857143 0.10501340558669281\n",
      "NON-VAGUE_FULL_DATASET: 84 6.678571428571429 0.10992494218344546\n",
      "EUPH_VAGUE_FULL_DATASET: 42 7.714285714285714 0.11850759989497742\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 42 5.071428571428571 0.09151921127840827\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 42 6.833333333333333 0.12102549987100723\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 42 6.523809523809524 0.09882438449588367\n",
      "\n",
      "test_5.csv\n",
      "EUPH_FULL_DATASET: 84 7.916666666666667 0.12951233360781722\n",
      "NON-EUPH_FULL_DATASET: 84 6.607142857142857 0.10438859739702891\n",
      "VAGUE_FULL_DATASET: 84 7.404761904761905 0.11704052686851671\n",
      "NON-VAGUE_FULL_DATASET: 84 7.119047619047619 0.11686040413632938\n",
      "EUPH_VAGUE_FULL_DATASET: 42 8.380952380952381 0.13600639411713103\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 42 6.428571428571429 0.0980746596199024\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 42 7.4523809523809526 0.12301827309850333\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 42 6.785714285714286 0.1107025351741554\n",
      "\n",
      "test_6.csv\n",
      "EUPH_FULL_DATASET: 84 8.726190476190476 0.13241389871733938\n",
      "NON-EUPH_FULL_DATASET: 84 5.857142857142857 0.10212961591387756\n",
      "VAGUE_FULL_DATASET: 84 6.392857142857143 0.1056172248229206\n",
      "NON-VAGUE_FULL_DATASET: 84 8.19047619047619 0.12892628980829632\n",
      "EUPH_VAGUE_FULL_DATASET: 42 7.0476190476190474 0.12038842687702044\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 42 5.738095238095238 0.09084602276882066\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 42 10.404761904761905 0.14443937055765826\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 42 5.976190476190476 0.11341320905893443\n",
      "\n",
      "test_7.csv\n",
      "EUPH_FULL_DATASET: 84 8.142857142857142 0.1321842102127681\n",
      "NON-EUPH_FULL_DATASET: 84 6.285714285714286 0.10124644898379828\n",
      "VAGUE_FULL_DATASET: 84 7.440476190476191 0.1157671534336386\n",
      "NON-VAGUE_FULL_DATASET: 84 6.988095238095238 0.11766350576292779\n",
      "EUPH_VAGUE_FULL_DATASET: 42 7.619047619047619 0.12319979961820511\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 42 7.261904761904762 0.10833450724907223\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 42 8.666666666666666 0.1411686208073312\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 42 5.309523809523809 0.09415839071852442\n",
      "\n",
      "test_8.csv\n",
      "EUPH_FULL_DATASET: 84 9.0 0.1314917124804575\n",
      "NON-EUPH_FULL_DATASET: 84 6.142857142857143 0.09648793624838639\n",
      "VAGUE_FULL_DATASET: 84 7.2023809523809526 0.10759732783794777\n",
      "NON-VAGUE_FULL_DATASET: 84 7.940476190476191 0.12038232089089612\n",
      "EUPH_VAGUE_FULL_DATASET: 42 7.690476190476191 0.1175417510276812\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 42 6.714285714285714 0.0976529046482143\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 42 10.30952380952381 0.14544167393323387\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 42 5.571428571428571 0.09532296784855854\n",
      "\n",
      "test_9.csv\n",
      "EUPH_FULL_DATASET: 84 8.904761904761905 0.14597381915842467\n",
      "NON-EUPH_FULL_DATASET: 84 5.142857142857143 0.09085379921945114\n",
      "VAGUE_FULL_DATASET: 84 7.4523809523809526 0.11773634456645861\n",
      "NON-VAGUE_FULL_DATASET: 84 6.595238095238095 0.1190912738114172\n",
      "EUPH_VAGUE_FULL_DATASET: 42 9.261904761904763 0.14225015096495836\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 42 5.642857142857143 0.09322253816795893\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 42 8.547619047619047 0.14969748735189103\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 42 4.642857142857143 0.08848506027094334\n",
      "\n",
      "train_0.csv\n",
      "EUPH_FULL_DATASET: 332 7.765060240963855 0.12595375874258452\n",
      "NON-EUPH_FULL_DATASET: 332 5.566265060240964 0.094881937731281\n",
      "VAGUE_FULL_DATASET: 332 6.707831325301205 0.10885766380265227\n",
      "NON-VAGUE_FULL_DATASET: 332 6.623493975903615 0.11197803267121331\n",
      "EUPH_VAGUE_FULL_DATASET: 166 7.927710843373494 0.12376756407399642\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 166 5.4879518072289155 0.09394776353130818\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 166 7.602409638554217 0.12813995341117276\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 166 5.644578313253012 0.09581611193125394\n",
      "\n",
      "train_1.csv\n",
      "EUPH_FULL_DATASET: 332 7.936746987951807 0.13186373149077077\n",
      "NON-EUPH_FULL_DATASET: 332 5.725903614457831 0.0959384889309838\n",
      "VAGUE_FULL_DATASET: 332 7.024096385542169 0.11393110537959947\n",
      "NON-VAGUE_FULL_DATASET: 332 6.63855421686747 0.11387111504215518\n",
      "EUPH_VAGUE_FULL_DATASET: 166 7.9397590361445785 0.12732718876915805\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 166 6.108433734939759 0.10053502199004104\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 166 7.933734939759036 0.13640027421238377\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 166 5.343373493975903 0.0913419558719267\n",
      "\n",
      "train_2.csv\n",
      "EUPH_FULL_DATASET: 332 7.575301204819277 0.12881400439854962\n",
      "NON-EUPH_FULL_DATASET: 332 5.728915662650603 0.0938193988874203\n",
      "VAGUE_FULL_DATASET: 332 6.644578313253012 0.10870349860391933\n",
      "NON-VAGUE_FULL_DATASET: 332 6.659638554216867 0.11392990468205061\n",
      "EUPH_VAGUE_FULL_DATASET: 166 7.524096385542169 0.12554894149988055\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 166 5.765060240963855 0.09185805570795812\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 166 7.626506024096385 0.13207906729721852\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 166 5.692771084337349 0.09578074206688275\n",
      "\n",
      "train_3.csv\n",
      "EUPH_FULL_DATASET: 332 7.475903614457831 0.11913681967376337\n",
      "NON-EUPH_FULL_DATASET: 332 5.424698795180723 0.0919137714779695\n",
      "VAGUE_FULL_DATASET: 332 6.13855421686747 0.10106825611380879\n",
      "NON-VAGUE_FULL_DATASET: 332 6.7620481927710845 0.10998233503792415\n",
      "EUPH_VAGUE_FULL_DATASET: 166 7.228915662650603 0.11565022903926922\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 166 5.048192771084337 0.08648628318834832\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 166 7.72289156626506 0.12262341030825745\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 166 5.801204819277109 0.09734125976759075\n",
      "\n",
      "train_4.csv\n",
      "EUPH_FULL_DATASET: 332 8.36144578313253 0.13546196357266788\n",
      "NON-EUPH_FULL_DATASET: 332 5.448795180722891 0.09279526522268194\n",
      "VAGUE_FULL_DATASET: 332 6.822289156626506 0.11008456967836686\n",
      "NON-VAGUE_FULL_DATASET: 332 6.9879518072289155 0.11817265911698302\n",
      "EUPH_VAGUE_FULL_DATASET: 166 8.066265060240964 0.12794901211397572\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 166 5.578313253012048 0.09222012724275805\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 166 8.656626506024097 0.14297491503135992\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 166 5.319277108433735 0.09337040320260596\n",
      "\n",
      "train_5.csv\n",
      "EUPH_FULL_DATASET: 332 7.789156626506024 0.12449497862740548\n",
      "NON-EUPH_FULL_DATASET: 332 5.048192771084337 0.08560777484666042\n",
      "VAGUE_FULL_DATASET: 332 6.105421686746988 0.10087450254226825\n",
      "NON-VAGUE_FULL_DATASET: 332 6.731927710843373 0.10922825093179774\n",
      "EUPH_VAGUE_FULL_DATASET: 166 7.367469879518072 0.12089854336196963\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 166 4.843373493975903 0.08085046172256695\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 166 8.210843373493976 0.12809141389284137\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 166 5.253012048192771 0.09036508797075407\n",
      "\n",
      "train_6.csv\n",
      "EUPH_FULL_DATASET: 332 7.957831325301205 0.13262640999391878\n",
      "NON-EUPH_FULL_DATASET: 332 5.382530120481928 0.08619392879059377\n",
      "VAGUE_FULL_DATASET: 332 6.701807228915663 0.10553817612836833\n",
      "NON-VAGUE_FULL_DATASET: 332 6.63855421686747 0.1132821626561442\n",
      "EUPH_VAGUE_FULL_DATASET: 166 8.096385542168674 0.12836774949473256\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 166 5.307228915662651 0.08270860276200412\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 166 7.819277108433735 0.1368850704931049\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 166 5.457831325301205 0.08967925481918347\n",
      "\n",
      "train_7.csv\n",
      "EUPH_FULL_DATASET: 332 7.710843373493976 0.12172803932990371\n",
      "NON-EUPH_FULL_DATASET: 332 5.385542168674699 0.09108771032664502\n",
      "VAGUE_FULL_DATASET: 332 6.72289156626506 0.108418291951968\n",
      "NON-VAGUE_FULL_DATASET: 332 6.373493975903615 0.10439745770458077\n",
      "EUPH_VAGUE_FULL_DATASET: 166 8.301204819277109 0.12921211909571617\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 166 5.144578313253012 0.08762446480821984\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 166 7.120481927710843 0.11424395956409113\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 166 5.626506024096385 0.09455095584507035\n",
      "\n",
      "train_8.csv\n",
      "EUPH_FULL_DATASET: 332 7.539156626506024 0.12411994517867933\n",
      "NON-EUPH_FULL_DATASET: 332 5.427710843373494 0.09355347117261584\n",
      "VAGUE_FULL_DATASET: 332 6.493975903614458 0.10788119605443858\n",
      "NON-VAGUE_FULL_DATASET: 332 6.47289156626506 0.10979222029685666\n",
      "EUPH_VAGUE_FULL_DATASET: 166 7.692771084337349 0.12291175356376736\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 166 5.295180722891566 0.09285063854510997\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 166 7.385542168674699 0.1253281367935915\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 166 5.5602409638554215 0.09425630380012195\n",
      "\n",
      "train_9.csv\n",
      "EUPH_FULL_DATASET: 332 7.608433734939759 0.12599400122305474\n",
      "NON-EUPH_FULL_DATASET: 332 5.644578313253012 0.09311802260793296\n",
      "VAGUE_FULL_DATASET: 332 6.873493975903615 0.11071372090625442\n",
      "NON-VAGUE_FULL_DATASET: 332 6.379518072289157 0.10839830292473339\n",
      "EUPH_VAGUE_FULL_DATASET: 166 8.25301204819277 0.13117777339832978\n",
      "NON-EUPH_VAGUE_FULL_DATASET: 166 5.493975903614458 0.0902496684141788\n",
      "EUPH_NON-VAGUE_FULL_DATASET: 166 6.963855421686747 0.1208102290477796\n",
      "NON-EUPH_NON-VAGUE_FULL_DATASET: 166 5.795180722891566 0.09598637680168727\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "for file in os.listdir('TEST_4.0'):\n",
    "    # if (file[0:4] != 'test'):\n",
    "    #     continue\n",
    "    full_df = pd.read_csv('TEST_4.0/' + file, index_col=0)\n",
    "    # df = pd.read_csv(\"Vagueness_Errors_1.0.csv\", index_col=0)\n",
    "\n",
    "    full_df['topic_sim_sum'] = -1\n",
    "    full_df['topic_sim_index'] = -1\n",
    "\n",
    "    topic_list = ['politics', 'death', 'kill', 'crime',\n",
    "           'drugs', 'alcohol', 'fat', 'old', 'poor', 'cheap',\n",
    "           'sex', 'sexual',\n",
    "           'employment', 'job', 'disability',\n",
    "           'pregnant', 'bathroom', 'sickness', \n",
    "            'race', 'racial', 'religion', 'government'\n",
    "          ]\n",
    "\n",
    "    # topic_list = ['die', 'kill']\n",
    "\n",
    "    for i, row in full_df.iterrows():\n",
    "        text = full_df.loc[i, 'edited_text']\n",
    "        text = preprocess(text)\n",
    "        # print(text)\n",
    "        words = text.split()\n",
    "        # print(words)\n",
    "        total_sim = 0 # total amount of topic similarity\n",
    "        for word in words:\n",
    "            if (word in stopwords):\n",
    "                continue\n",
    "            sim = sum_similarity(model, word, topic_list)\n",
    "            if (sim == -1):\n",
    "                total_sim += 10\n",
    "            else:\n",
    "                total_sim += sim\n",
    "            #print(word, sim)\n",
    "        full_df.loc[i, 'topic_sim_sum'] = total_sim\n",
    "        full_df.loc[i, 'topic_sim_index'] = total_sim/len(words)\n",
    "\n",
    "    print(file)\n",
    "    euph_examples = full_df.loc[full_df['is_euph'] == 1]\n",
    "    noneuph_examples = full_df.loc[full_df['is_euph'] == 0]\n",
    "    vague_examples = full_df.loc[full_df['is_vague'] == 1]\n",
    "    nonvague_examples = full_df.loc[full_df['is_vague'] == 0]\n",
    "    euph_vague_examples = euph_examples.loc[euph_examples['is_vague']==1]\n",
    "    noneuph_vague_examples = noneuph_examples.loc[noneuph_examples['is_vague']==1]\n",
    "    euph_nonvague_examples = euph_examples.loc[euph_examples['is_vague']==0]\n",
    "    noneuph_nonvague_examples = noneuph_examples.loc[noneuph_examples['is_vague']==0]\n",
    "    # print(euph_examples.loc[:, 'topic_sim_sum'].mean())\n",
    "    # print(noneuph_examples.loc[:, 'topic_sim_sum'].mean())\n",
    "    print(\"EUPH_FULL_DATASET:\", len(euph_examples), euph_examples.loc[:, 'topic_sim_sum'].mean(), euph_examples.loc[:, 'topic_sim_index'].mean())\n",
    "    print(\"NON-EUPH_FULL_DATASET:\", len(noneuph_examples), noneuph_examples.loc[:, 'topic_sim_sum'].mean(), noneuph_examples.loc[:, 'topic_sim_index'].mean())\n",
    "    print(\"VAGUE_FULL_DATASET:\", len(vague_examples), vague_examples.loc[:, 'topic_sim_sum'].mean(), vague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "    print(\"NON-VAGUE_FULL_DATASET:\", len(nonvague_examples), nonvague_examples.loc[:, 'topic_sim_sum'].mean(), nonvague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "    print(\"EUPH_VAGUE_FULL_DATASET:\", len(euph_vague_examples), euph_vague_examples.loc[:, 'topic_sim_sum'].mean(), euph_vague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "    print(\"NON-EUPH_VAGUE_FULL_DATASET:\", len(noneuph_vague_examples), noneuph_vague_examples.loc[:, 'topic_sim_sum'].mean(), noneuph_vague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "    print(\"EUPH_NON-VAGUE_FULL_DATASET:\", len(euph_nonvague_examples), euph_nonvague_examples.loc[:, 'topic_sim_sum'].mean(), euph_nonvague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "    print(\"NON-EUPH_NON-VAGUE_FULL_DATASET:\", len(noneuph_nonvague_examples), noneuph_nonvague_examples.loc[:, 'topic_sim_sum'].mean(), noneuph_nonvague_examples.loc[:, 'topic_sim_index'].mean())\n",
    "    print()\n",
    "\n",
    "    # df['topic_sim_sum'] = -1\n",
    "    # df['topic_sim_index'] = -1\n",
    "\n",
    "    # for i, row in df.iterrows():\n",
    "    #     text = df.loc[i, 'edited_text']\n",
    "    #     text = preprocess(text)\n",
    "    #     # print(text)\n",
    "    #     words = text.split()\n",
    "    #     # print(words)\n",
    "    #     total_sim = 0 # total amount of topic similarity\n",
    "    #     for word in words:\n",
    "    #         if (word in stopwords):\n",
    "    #             continue\n",
    "    #         sim = sum_similarity(model, word, topic_list)\n",
    "    #         if (sim == -1):\n",
    "    #             total_sim += 10\n",
    "    #         else:\n",
    "    #             total_sim += sim\n",
    "    #         #print(word, sim)\n",
    "    #     df.loc[i, 'topic_sim_sum'] = total_sim\n",
    "    #     df.loc[i, 'topic_sim_index'] = total_sim/len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87722f9a-b294-4277-b6f1-d7814c31990f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "euphemismEnv",
   "language": "python",
   "name": "euphemismenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
